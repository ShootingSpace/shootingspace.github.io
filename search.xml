<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[算法与数据结构 10 - Java | LinkedList 还是 ArrayList - CS61B Berkeley]]></title>
    <url>%2FNOTE-CS61B-data-structures-10-java-which-list%2F</url>
    <content type="text"><![CDATA[Java 提供了 ArrayList, ArrayDeque 和 LinkedList 几个API.队列 queue, 通俗的含义, 就是不能插队, 只能在末尾插入.Deque 就是双端队列 Double Ended Queue。双端队列是具有动态大小的序列容器，可以在两端（前端或后端）扩展或收缩（定义来源 cplusplus.com）. CS61b的project 1a就是实现两种双端队列（array based 和 linkedklist based）. 不同的API, 在考虑什么时候应该用哪个时, 我们需要考虑它们的性能差异: 搜索/定位：与LinkedList搜索操作相比，ArrayList搜索操作更快。 ArrayList的get(int index)性能是O(1)的，而LinkedList的性能是O(n)。因为ArrayList基于array数据结构，可以直接用靠 array index 索引元素。 删除/插入：LinkedList 操作性能是O(1)，而ArrayList的性能从O(n)（删除/插入第一个元素）到O(n)（最后一个元素）都有可能。因为LinkedList的每个元素都包含两个指向其相邻前后元素的指针（地址），因此仅需要改变，被删节点的prev和next指针位置。而在ArrayList中，需要移动剩余元素，来重新填充array空间。 内存开销：LinkedList的每个元素都有更多的内存开销(额外的指针), 而ArrayLists没有这个开销。但是，ArrayLists需要占用初始容量。一般ArrayList的默认初始容量非常小（Java 1.4 - 1.8使用10）。但是，往ArrayLists添加元素时， 它可能会适当地增大容量，所以如果添加了很多元素，则必须不断调整数组的大小，那样也可能会导致元素频繁挪动位置。 综上所述： 如果在应用中需要频繁插入和删除，那么选择LinkedList。 假如一开始，就知道后面要添加大量元素，那就使用较高的初始容量来构造ArrayList。 大部分用例中, 相比LinkedList, 人们更偏爱ArrayList以及ArrayDeque。如果你不确定应该选哪个, 那么就直接考虑ArrayList吧(参考).]]></content>
      <categories>
        <category>学习笔记</category>
        <category>计算机科学</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>Java</tag>
        <tag>软件工程</tag>
        <tag>数据结构</tag>
        <tag>算法</tag>
        <tag>cs61b</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[抽象编程 - C++ 算法与数据结构 Stanford cs106b]]></title>
    <url>%2FNOTE-CS106B-Programming-Abstractions-Stanford%2F</url>
    <content type="text"><![CDATA[Note CS106B Stanford Programming AbstractionsTopics:Recursion, algorithms analysis (sort/search/hash), dynamic data structures (lists, trees, heaps), data abstraction (stacks, queues, maps), implementation strategies/tradeoffs Purposes: become acquainted with the C++ programming language learn more advanced programming techniques explore classic data structures and algorithms and apply these tools to solving complex problemsReference Text Book: Data Structures &amp; Algorithm Analysis in C++, 4th ed, by Mark A. Weiss Text Book: Programming Abstractions in C++ 1st Edition by Eric Roberts Text Book: Algorithms, 4th Edition Blog: Red Blob Games, Amit’s A* Pages Coding style Works correctly in all situations: Using a listing of specific test cases to exercise the program on. The overall approach is straight-forward, data structure is cleanly organized, tasks are nicely decomposed, algorithms are clear and easy to follow, comments are helpful, layout is consistent.CommentingExamples of information you might include in comments: General overview. What are the goals and requirements of this program? this function? The overview comment should also contain author and version information: who worked on this file and when. Data structures. How is the data stored? How is it ordered, searched, accessed? Design decisions. Why was a particular data structure or algorithm chosen? What other strategies were tried and rejected? Error handling. How are error conditions handled? What assumptions are made? What happens if those assumptions are violated? Nitty-gritty code details. Comments are invaluable for explaining the inner workings of particularly complicated (often labeled “clever”) paths of the code. Planning for the future. How might one make modifications or extensions later? And more… (This list is by no means exhaustive) ADTDefinitionAn abstract data type is a set of objects together with a set of operations. Abstract data types are mathematical abstractions; nowhere in an ADT’s definition is there any mention of how the set of operations is implemented.Objects such as lists, sets, and graphs, along with their operations, can be viewed as ADTs.Also there are search tree, set, hash table, priority queue. Client uses class as abstraction Invokes public operations only Internal implementation not relevant! Client can’t and shouldn’t muck with internals Class data should private Imagine a “wall” between client and implementor Wall prevents either from getting involved in other’s business Interface is the “chink” in the wall Conduit allows controlled access between the two Consider Lexicon Abstraction is a word list, operations to verify word/prefix How does it store list? using array? vector? set? does it matter to client? Why ADTs? Abstraction: Client insulated from details, works at higher-level Encapsulation: Internals private to ADT, not accessible by client Independence: Separate tasks for each side (once agreed on interface) Flexibility: ADT implementation can be changed without affecting client Vector and list in the STLThe C++ language includes, in its library, an implementation of common data structures.This part of the language is popularly known as the Standard Template Library (STL). In general, these data structures are called collections or containers. IteratorsIn the STL, a position is represented by a nested type, iterator. Getting an Iterator iterator begin( ) returns an appropriate iterator representing the first item in thecontainer. iterator end( ) returns an appropriate iterator representing the endmarker in thecontainer (i.e., the position after the last item in the container). Iterator Methods itr++ and ++itr advances the iterator itr to the next location. Both the prefix and postfix forms are allowable. itr returns a reference to the object stored at iterator itr’s location. The reference returned may or may not be modifiable (we discuss these details shortly). itr1==itr2 returns true if iterators itr1 and itr2 refer to the same location and false otherwise. itr1!=itr2 returns true if iterators itr1 and itr2 refer to a different location and false otherwise. Container Operations that require IteratorsThe three most popular methods that require iterators are those that add or remove from the list (either a vector or list) at a specified position: iterator insert( iterator pos, const Object &amp; x ): adds x into the list, prior to theposition given by the iterator pos. This is a constant-time operation for list, but not forvector. The return value is an iterator representing the position of the inserted item. iterator erase( iterator pos ): removes the object at the position given by the iterator. This is a constant-time operation for list, but not for vector. The return value is the position of the element that followed pos prior to the call. This operation invalidates pos, which is now stale, since the container item it was viewing has been removed. iterator erase( iterator start, iterator end ): removes all items beginning at position start, up to, but not including end. Observe that the entire list can be erased by the call c.erase( c.begin( ), c.end( ) ) Range for loopC++11 also allows the use of the reserved word auto to signify that the compiler will automatically infer the appropriate type, for simple data type: 12for( auto x : squares ) cout&lt;&lt; x; for complicate data type like map: Each element of the container is a map&lt;K, V&gt;::value_type, which is a typedef for std::pair&lt;const K, V&gt;. Consequently, you’d write this as 123for (auto&amp; kv : myMap) &#123; std::cout &lt;&lt; kv.first &lt;&lt; " has value " &lt;&lt; kv.second &lt;&lt; std::endl;&#125; RecursionHelper Function No clear definition of helper function How to utilize helper function to help constructing recursion algarithm: construct a same-name recursive function with extra parameters to pass in. In some other cases, decomposition with several step into a function is itself a helper function, which help to make the main function simple and clean. Exhaustive recursionPermutations/subsets are about choice Both have deep/wide tree of recursive calls Depth represents total number of decisions made Width of branching represents number of available options per decision Explores every possible option at every decision point, typically very expensive, N! permutations, 2N subsets Recursive BacktrackingPartial exploration of exhaustive space. In the case that if we are interested in finding any solution, whichever one that works out first is fine. If we eventually reach our goal from here, we have no need to consider the paths not taken. However, if this choice didn’t work out and eventually leads to nothing but dead ends; when we backtrack to this decision point, we try one of the other alternatives. The back track based on the stacks of recursion, if a stack return false (or fail result), we back to previous stack and try another way(un-making choice). Need something return(normally bool) to step out of the entire recursion once any one solution found. One great tip for writing a backtracking function is to abstract away the details of managing the configuration (what choices are available, making a choice, checking for success, etc.) into other helper functions so that the body of the recursion itself is as clean as can be. This helps to make sure you have the heart of the algorithm correct and allows the other pieces to be developed, test, and debugged independently. PointerlvalueIn C++, any expression that refers to an internal memory location capable of storing data is called an lvalue (pronounced “ell-value”).x = 1.0; Declaring pointer variables123456789101112131415161718192021222324252627282930313233int main() &#123; -------------------------------------------------- // Declaration, in the stack // Not yet initialized! int num; int *p, *q; // If cout &lt;&lt; num &lt;&lt; p &lt;&lt; q &lt;&lt; endl; // There will be junk number, junk address. // If now *p=10, it may blow up, because what *p point to is an address points to somewhere around that could be invalid. --------------------------------------------------- // new operator allocate memory from the heap, returns address p = new int; // P -----&gt; [ int ] （heep 1000） *p = 10; // P -----&gt; [ 10 ] （heep 1000） q = new int; // P -----&gt; [ int ] （heep 1004） *q = *p; // q -----&gt; [ 10 ] （heep 1004） q = p; // q -----&gt; [ 10 ] （heep 1000） // [ 10 ] （heep 1004） became orphan, and could not be reclaim back --------------------------------------------------- delete p; // [ 10 ] （heep 1000）memory was reclaimed and free, // and available for others as [ ]（heep 1000）, // but p still hold the address delete q; // bad idea, [ 10 ]（heep 1000） already been reclaimed! q = NULL; // NULL is zero pointer, means the pointer does not hold any address, // used as sentinel value, sometimes better than delete. // Accessing "deleted" memory has unpredictable consequences --------------------------------------------------- // int *p declaration reserves only a single word, which is large enough to hold a machine address. // ≠ // int *p = NULL declare pointer p as nullptr --------------------------------------------------- (*newOne).name = name // "." &gt; "*" newOne-&gt;name = name Use of pointerBig program that contains a certain amout of classes and objects that are share some relationship. Instead of copying data from each other, using pointer to point to specific data is better: Saves space by not repeating the same information. If some objects gets new information to update, change in one place only! Dynamic allocation Request memoryTo acquire new memory when you need it and to free it explicitly when it is no longer needed. Acquiring new storage when the program is running. While the program is running, you can reserve part of the unallocated memory, leaving the rest for subsequent allocations.The pool of unallocated memory available to a program is called the heap.int *p = new int; //new operator to allocate memory from the heapIn its simplest form, the new operator takes a type and allocates space for a variable of that type located in the heap.The call to new operator will return the address of a storage location in the heap that has been set aside to hold an integer. Free occupied memoryDelete which takes a pointer previously allocated by new and returns the memory associated with that pointer to the heap. TreeTree terminology Node, tree, subtree, parent, child, root, edge, leaf For any node ni, the depth of ni is the length of the unique path from the root to ni. The height of ni is the length of the longest path from ni to a leaf Rules for all trees Recursive branching structure Single root node Every node reachable from root by unique path Binary treeEach node has at most 2 children. Binary search tree All nodes in left subtree are less than root, all nodes in right subtree are greater. Arranged for efficient search/insert. It is the basis for the implementation of two library collections classes, set and map. Most operations’ average running time is O(log N). Operating on trees Many tree algorithms are recursive Handle current node, recur on subtrees Base case is empty tree (NULL) Tree traversals to visit all nodes, order of traversal: Pre: cur, left, right In: left, cur, right Post: left, right, cur Others: level-by-level, reverse orders, etc Balanced Search TreesBinary search tree have poor worst-case performance.To make costs are guaranteed to be logarithmic, no matter what sequence of keys is used to construct them, the ideal is to keep binary search trees perfectly balanced. Unfortunately, maintaining perfect balance for dynamic insertions is too expensive. So consider data structure that slightly relaxes the perfect balance requirement to provide guaranteed logarithmic performance not just for the insert and search operations, but also for all of the ordered operations (except range search). AVL treeAdelson-Velskii and Landis tree is a binary search tree with a balance condition. Track balance factor for each node: Height of right subtree - height of left subtree information is kept for each node (in the node structure) For every node in the tree, the height of the left and right subtrees can differ by at most 1 (Balance factor = 0 or 1). When balance factor hits 2, restructure Rotation moves nodes from heavy to light side Local rearrangement around specific node When finished, node has 0 balance factor Single rotation: one time rotation between new insert node and its parent node Double rotation: two single rotation of the new insert node 2-3 treesAllow the nodes in the tree to hold more than one key: 3-nodes, which hold three links and two keys. Definition: A 2-3 search tree is a tree that is either empty or A 2-node, with one key (and associated value) and two links, a left link to a 2-3 search tree with smaller keys, and a right link to a 2-3 search tree with larger keys A 3-node, with two keys (and associated values) and three links, a left link to a 2-3 search tree with smaller keys, a middle link to a 2-3 search tree with keys between the node’s keys, and a right link to a 2-3 search tree with larger keys A perfectly balanced 2-3 search tree is one whose null links are all the same distance from the root. The concept guarantee that search and insert operations in a 2-3 tree with N keys are to visit at most lg N nodes. But its dicrect implementation is inconvenient: Not only is there a substantial amount of code involved, but the overhead incurred could make the algorithms slower than standard BST search and insert. Consider a simple representation known as a red-black BST that leads to a natural implementation. Priority QueuesA priority queue is a data structure that allows at least the following two operations: insert, and deleteMin, which finds, returns, and removes the minimum element in the priority queue. Binary HeapA heap is a binary tree that is completely filled, with the possible exception of the bottom level, which is filled from left to right. Such a tree is known as a complete binary tree. Structure A heap data structure consist of an array (of Comparable objects) and an integer representing the current heap size. For any element in array position i, the left child is in position 2i, the right child is in the cell after the left child [2i + 1], and the parent is in position [i/2]. Heap-Order Property For every node X, the key in the parent of X is smaller than (or equal to) the key in X. So to make find minimum operation quick. Basic Heap Operation insert: To insert an element X into the heap, create a hole in the next available location. Then Percolate up - swap X with its parent index (i/2) so long as X has a higher priority than its parent. Continue this process until X has no more lower priority parent. 1234567//Percolate upint hole = ++size; binaryQueue[0]=std::move(*newOne); for (;(priority&lt;binaryQueue[hole/2].priority || (priority==binaryQueue[hole/2].priority &amp;&amp; name&lt;binaryQueue[hole/2].name) );hole/=2) &#123; binaryQueue[hole] = std::move(binaryQueue[hole/2]); &#125; binaryQueue[hole] = std::move(binaryQueue[0]); deleteMin: When the minimum is removed, a hole is created at the root. Move the last element X in the heap to place in the root hole. Then Percolate down - swapp X with its more urgent-priority child [index (i2 or i2+1)] so long as it has a lower priority than its child. Repeat this step until X has no more higher priority child. 1234567891011//Percolate downint child; for (; hole*2&lt;=size;hole=child) &#123; child = hole*2; if ( child!=size &amp;&amp; (binaryQueue[child+1].priority&lt;binaryQueue[child].priority || (binaryQueue[child+1].priority==binaryQueue[child].priority &amp;&amp; binaryQueue[child+1].name&lt;binaryQueue[child].name)) ) ++child; if ( binaryQueue[child].priority&lt;priority_tobePerD || (binaryQueue[child].priority==priority_tobePerD &amp;&amp; binaryQueue[child].name&lt;name_tobePerD) ) &#123; binaryQueue[hole] = std::move(binaryQueue[child]); &#125; else break; &#125; Use integer division to avoid even odd index. Algorithm AnalysisSpace/time, big-O, scalability Big-O Computational complexity: The relationship between N and the performance of an algorithm as N becomes large Big-O notation: to denote the computational complexity of algorithms. Standard simplifications of big-O Eliminate any term whose contribution to the total ceases to be significant as N becomes large. Eliminate any constant factors. Worst-case versus average-case complexityAverage-case performance often reflects typical behavior, while worst-case performance represents a guarantee for performance on any possible input. Predicting computational complexity from code structure Constant time: Code whose execution time does not depend on the problem size is said to run in constant time, which is expressed in big-O notation as O(1). Linear time: function that are executed exactly n times, once for each cycle of the for loop, O(N) Quadratic time: Algorithms like selection sort that exhibit O(N2) performance are said to run in quadratic tim For many programs, you can determine the computational complexity simply by finding the piece of the code that is executed most often and determining how many times it runs as a function of N Space/time In general, the most important measure of performance is execution time. It also possible to apply complexity analysis to the amount of memory space required. Nowadays the memory is cheap, but it still matters when designing extreamly big programs, or APPs on small memory device, such as phones and wearable devices. SortingThere are lots of different sorting algoritms, from the simple to very complex. Some optimized for certain situations (lots of duplicates, almost sorted, etc.). So why do we need multiple algorithms? Selection sort Select smallest and swap to front/backend 12345678910void SelectionSort(Vector&lt;int&gt; &amp;arr)&#123; for (int i = 0; i &lt; arr.size()-1; i++) &#123; int minIndex = i; for (int j = i+1; j &lt; arr.size(); j++) &#123; if (arr[j] &lt; arr[minIndex]) minIndex = j; &#125; Swap(arr[i], arr[minIndex]); &#125; Selection sort analysisCount work inside loops: First iteration does N-1 compares, second does N-2, and so on. One swap per iteration O(N2) Insertion sort As sorting hand of just-dealt cards, each subsequent element inserted into proper place Start with first element (already sorted) Insert next element relative to first Repeat for third, fourth, etc. Slide elements over to make space during insert123456789void InsertionSort(Vector&lt;int&gt; &amp;v)&#123; for (int i = 1; i &lt; v.size(); i++) &#123; int cur = v[i]; // slide cur down into position to left for (int j=i-1; j &gt;= 0 &amp;&amp; v[j] &gt; cur; j--) v[j+1] = v[j]; v[j+1] = cur; &#125;&#125; Insertion sort analysisBecause of the nested loops, each of which can take N iterations, insertion sort is O(N2). HeapsortPriority queues can be used to sort in O(N log N) time. The algorithm based on this idea is known as heapsort. Heapsort analysisThe building of the heap, uses less than 2N comparisons. In the second phase, the ith deleteMax uses at most less than 2*log (N − i + 1) comparisons, for a total of at most 2N log N − O(N) comparisons (assuming N ≥ 2). Consequently, in the worst case, at most 2N log N − O(N) comparisons are used by heapsort. Merge sort Inspiration: Algorithm like selection sort is quadratic growth (O(N2)). Double input -&gt; 4X time, halve input -&gt; 1/4 time.Can recursion save the day? If there are two sorted halves, how to produce sorted full result? Divide and conquer algorithm Divide input in half Recursively sort each half Merge two halves together “Easy-split hard-join” No complex decision about which goes where, just divide in middle Merge step preserves ordering from each half Merge depends on the fact that the first element in the complete ordering must be either the first element in v1 or the first element in v2, whichever is smaller. 12345678910111213141516171819202122232425void MergeSort(Vector&lt;int&gt; &amp;v)&#123; if (v.size() &gt; 1) &#123; int n1 = v.size()/2; int n2 = v.size() - n1; Vector&lt;int&gt; left = Copy(v, 0, n1); Vector&lt;int&gt; right = Copy(v, n1, n2); MergeSort(left); MergeSort(right); v.clear(); Merge(v, left, right); &#125;&#125;void Merge(Vector&lt;int&gt; &amp;v,Vector&lt;int&gt; &amp;left,Vector&lt;int&gt; &amp;right) &#123; int l=0, r=0; while(l&lt;left.size() &amp;&amp; r&lt;right.size()) &#123; if (left[l]&lt;right[r]) v.add(left[l++]); else v.add(right[r++]); &#125; while(l&lt;left.size()) v.add(left[l++]); while(r&lt;right.size()) v.add(right[r++]);&#125; Mergesort analysisThe time to mergesort N numbers is equal to the time to do two recursive mergesorts of size N/2, plus the time to merge, which is linear. T(N) = N + 2T(N/2). log N levels * N per level= O(NlogN). Mergesort uses the lowest number of comparisons of all the popular sorting algorithms.Theoretical result show that no general sort algorithm could be better than NlogN.But there is still better in practice: The running time of mergesort, when compared with other O(N log N) alternatives, depends heavily on the relative costs of comparing elements and moving elements in the array (and the temporary array). These costs are language dependent. In Java, when performing a generic sort (using a Comparator), an element comparison can be expensive, but moving elements is cheap (because they are reference assignments, rather than copies of large objects). In C++, in a generic sort, copying objects can be expensive if the objects are large, while comparing objects often is relatively cheap because of the ability of the compiler to aggressively perform inline optimization. QuicksortMost sorting programs in use today are based on an algorithm called Quicksort, which employs a Divide and conquer strategy as merge sort, but instead take a different approach to divide up input vector into low half and high half. Quicksort uses a few more comparisons, in exchange for significantly fewer data movements. The reason that quicksort is faster is that the partitioning step can actually be performed in place and very efficiently. “Hard-split easy-join”, Each element examined and placed in correct half, so that join step become trivial. Choose an element (pivot) to serve as the boundary between the small and large elements. Partitioning: Rearrange the elements in the vector so that all elements to the left of the boundary are less than the pivot and all elements to the right are greater than or possibly equal to the pivot. Sort the elements in each of the partial vectors.12345678void Quicksort(Vector&lt;int&gt; &amp;v, int start, int stop)&#123; if (stop &gt; start) &#123; int pivot = Partition(v, start, stop); Quicksort(v, start, pivot-1); Quicksort(v, pivot+1, stop); &#125;&#125; Quicksort performance analysisThe running time of quicksort is equal to the running time of the two recursive calls plus the linear time spent in the partition (the pivot selection takes only constant time). T(N) = T(i) + T(N − i − 1) + cN, where i = |S1| is the number of elements in S1.There are thre cases Ideal 50/50 split: The pivot is in the middle, T(N) = cN + 2T(N/2) =&gt; O(NlogN) Average bad 90/10 split: N per level, but more levels, solve N*(9/10)k = 1, still k = O(NlogN) Worst N-1/1 split: The pivot is the smallest element, all the time. Then i = 0, T(N) = T(N − 1) + cN, N &gt; 1. With N levels! O(N2) In a vector with randomly chosen elements, Quicksort tends to perform well, with an average-case complexity of O(N log N). In the worst case — which paradoxically consists of a vector that is already sorted — the performance degenerates to O(N2). Despite this inferior behavior in the worst case, Quicksort is so much faster in practice than most other algorithms that it has become the standard. Design StrategyWhen an algorithm is given, the actual data structures need not be specified. It is up to the programmer to choose the appropriate data structure in order to make the running time as small as possible. There are many to be considered: algorithms, data structure, space-time tradeoff, code complexity. Dynamic ProgrammingTo solve optimization problems in which we make a set of choices in order to arrive at an optimal solution. As we make each choice, subproblems of the same form often arise. Dynamic programming is effective when a given subproblem may arise from more than one partial set of choices; the key technique is to store the solution to each such subproblem in case it should reappear. Unlike divide-and-conquer algorithms which partition the problem into disjoint subproblems, dynamic programming applies when the subproblems overlap. “Programming” in this context refers to a tabular method. When should look for a dynamic-programming solution to a problem? Optimal substructure: a problem exhibits optimal substructure if an optimal solution to the problem contains within it optimal solutions to subproblems. Overlapping subproblems: When a recursive algorithm revisits the same problem repeatedly, we say that the optimization problemhas overlapping subproblems. In contrast, a problem for which a divide-andconquer approach is suitable usually generates brand-new problems at each step of the recursion. General setps of Dynamic Programming Characterize the structure of an optimal solution. Recursively define the value of an optimal solution. Compute the value of an optimal solution, typically in a bottom-up fashion. Construct an optimal solution from computed information. Greedy AlgorithmsGreedy algorithms work in phases. In each phase, a decision is made in a locally optimal manner, without regard for future consequences. When the algorithm terminates, we hope that the local optimum is equal to the global optimum. If this is the case, then the algorithm is correct; otherwise, the algorithm has produced a suboptimal solution. Huffman Codes A Huffman code is a particular type of optimal prefix code that is commonly used for lossless data compression. The reason that this is a greedy algorithm is that at each stage we perform a merge without regard to global considerations. We merely select the two smallest trees. If we maintain the trees in a priority queue, ordered by weight, then the running time is O(C logC), since there will be one buildHeap, 2C − 2 deleteMins, and C − 2 inserts. A simple implementation of the priority queue, using a list, would give an O(C2) algorithm. The choice of priority queue implementation depends on how large C is. In the typical case of an ASCII character set, C is small enough that the quadratic running time is acceptable. Divide and ConquerTraditionally, routines in which the text contains at least two recursive calls and subproblems be disjoint (that is, essentially nonoverlapping) are called divide-and-conquer algorithms. Divide: Smaller problems are solved recursively (except, of course, base cases). Conquer: The solution to the original problem is then formed from the solutions to the subproblems.We have already seen several divide-and-conquer algorithms: mergesort and quicksort, which have O(N log N) worst-case and averagecase bounds, respectively. Backtracking AlgorithmsSee Recursive BacktrackingIn some cases, the savings over a brute-force exhaustive search can be significant.The elimination of a large group of possibilities in one step is known as pruning. How to evaluate/compare alternatives Often interested in execution performance: Time spent and memory used Should also consider ease of developing, verifying, maintaining codeQuicksort strategy Picking the pivotPicking a good pivot improves performance, but also costs some time. If the algorithm spends more time choosing the pivot than it gets back from making a good choice, you will end up slowing down the implementation rather than speeding it up. The popular, uninformed choice is to use the first element as the pivot. This is acceptable if the input is random, but if the input is presorted or in reverse order, then the pivot provides a poor partition. A safe approach is to choose the pivot element randomly. On the other hand, random number generation is generally an expensive commodity and does not reduce the average running time of the rest of the algorithm at all. A good estimate can be obtained by picking three elements randomly and using the median of these three as pivot. The randomness turns out not to help much, so the common course is to use as pivot the median of the left, right, and center elements. Quicksort partitioning strategyA known method that is very easy to do it wrong or inefficiently. General process: The first step is to get the pivot element out of the way by swapping it with the last element. Two pointers, i point to the first element and j to the next-to-last element. What our partitioning stage wants to do is to move all the small elements to the left part of the array and all the large elements to the right part. “Small” and “large” are relative to the pivot. While i is to the left of j, we move i right, skipping over elements that are smaller than the pivot. We move j left, skipping over elements that are larger than the pivot. When i and j have stopped, i is pointing at a large element and j is pointing at a small element. If i is to the left of j (not yet cross), those elements are swapped. Repeat the process until i and j cross The final is to swap the pivot element with present i element One important detail we must consider is how to handle elements that are equal to the pivot? Suppose there are 10,000,000 elements, of which 500,000 are identical (or, more likely, complex elements whose sort keys are identical). To get an idea of what might be good, we consider the case where all the elements in the array are identical. If neither i nor j stops, and code is present to prevent them from running off the end of the array, no swaps will be performed. Although this seems good, a correct implementation would then swap the pivot into the last spot that i touched, which would be the next-to last position (or last, depending on the exact implementation). This would create very uneven subarrays. If all the elements are identical, the running time is O(N2). If both i and j stop, there will be many swaps between identical elements. The partition creates two nearly equal subarrays. The total running time would then be O(N log N). Thus it is better to do the unnecessary swaps and create even subarrays than to risk wildly uneven subarrays. Small arrays For very small arrays (N ≤ 20), quicksort does not perform as well as insertion sort. Furthermore, because quicksort is recursive, these cases will occur frequently. A common solution is not to use quicksort recursively for small arrays, but instead use a sorting algorithm that is efficient for small arrays, such as insertion sort. A good cutoff range is N = 10, although any cutoff between 5 and 20 is likely to produce similar results. This also saves nasty degenerate cases, such as taking the median of three elements when there are only one or two. Text editor case study Buffer requirements Sequence of characters + cursor position Operations to match commands above What to consider? Implementation choices performance implications Buffer class interface 1234567891011121314class Buffer &#123; public: Buffer(); ~Buffer(); void moveCursorForward(); void moveCursorBackward(); void moveCursorToStart(); void moveCursorToEnd(); void insertCharacter(char ch); void deleteCharacter(); void display(); private: // TBD!&#125;; Buffer layered on Vector Need character data + cursor Chars in Vector&lt;char&gt; Represent cursor as integer index Minor detail – is index before/after cursor? Buffer contains: AB|CDE 1234// for Buffer classprivate: Vector&lt;char&gt; chars;int cursor; Performance insertCharacter() and deleteCharacter() is linear, other operation is just O(1) Space used ~1 byte per char Buffer layered on Stack Inspiration: add/remove at end of vector is fast If chars next to cursor were at end… Build on top of stack? Another layered abstraction! How is cursor represented? Buffer contains:AB|CDEThere is no explicit cursor representation, instead using two stack to represent a whole data structure being seperated by the implicit cursor. 123// for Buffer classprivate: Stack&lt;char&gt; before, after; Performance moveCursorToStart(), moveCursorToEnd() operation is linear, other operation is just O(1) Space used ~2 byte per char Buffer as double linked list Inspiration: contiguous memory is constraining Connect chars without locality Add tail pointer to get direct access to last cell Add prev link to speed up moving backwards Buffer contains:AB|CDE 1234567// for Buffer classprivate: struct cellT &#123; char ch; cellT *prev, *next; &#125;; cellT *head, *tail, *cursor; Cursor design To cell before or after? 5 letters, 6 cursor positions… Add “dummy cell” to front of list Performance destruction is linear, other operation is just O(1) Space used ~9 byte per char Compare implementations table th:nth-of-type(1) { width: 200px; } table th:nth-of-type(2) { width: 80px; } table th:nth-of-type(3) { width: 80px; } Operation Vector Stack Single linked list Double linked list Buffer() O(1) O(1) O(1) O(1) ~Buffer() O(1) O(1) O(N) O(N) moveCursorForward() O(1) O(1) O(1) O(1) moveCursorBackward() O(1) O(1) O(N) O(1) moveCursorToStart() O(1) O(N) O(1) O(1) moveCursorToEnd() O(1) O(N) O(N) O(1) insertCharacter() O(N) O(1) O(1) O(1) deleteCharacter() O(N) O(1) O(1) O(1) Space used 1N 2N 5N 9N Space-time tradeoff Doubly-linked list is O(1) on all six operations But, each char uses 1 byte + 8 bytes of pointers =&gt; 89% overhead! Compromise: chunklist Array and linked list hybrid Shares overhead cost among several chars Chunksize can be tuned as appropriate Cost shows up in code complexity Cursor must traverse both within and across chunks Splitting/merging chunks on insert/deletes Implementing MapMap is super-useful, support any kind of dictionary, lookup table, index, database, etc.Map stores key-value pairs, support fast access via key, operations to optimize: add, getValueHow to make it work efficiently? Implement Map as Vector Layer on Vector, provides convenience with low overhead Define pair struct, to olds key and value together, Vector&lt;pair&gt; Vector sorted or unsorted? If sorted, sorted by what? Sorting: Provides fast lookup, but still slow to insert (because of shuffling) How to implement getValue, add? Does a linked list help? Easy to insert, once at a position But hard to find position to insert… Implementing Map as tree Implementatation Each Map entry adds node to tree, node contains: string key, client-type value, pointers to left/right subtrees Tree organized for binary search, Key is used as search field getValue: Searches tree, comparing keys, find existing match or error add: Searches tree, comparing keys, overwrites existing or adds new node Private members for Map 1234567891011121314151617template &lt;typename ValType&gt; class Map &#123; public: // as before private: struct node &#123; string key; ValType value; node *left, *right; &#125;; node *root; node *treeSearch(node * t, string key); void treeEnter(node *&amp;t, string key, ValType val); DISALLOW_COPYING(Map)&#125;; Evaluate Map as tree Space used: Overhead of two pointers per entry (typically 8 bytes total) Runtime performance: Add/getValue take time proportional to tree height(expected to be O(logN)) Degenerate trees The insert order is “sorted”: 2 8 14 15 18 20 21, totally unbalanced with height = 7 The insert order is “alternately sorted”: 21 2 20 8 14 15 18 or 2 8 21 20 18 14 15 Association: What is the relationship between worst-case inputs for tree insertion and Quicksort? What to do about it: AVL tree Compare Map implementations Operation Vector BST Sorted Vector getValue O(N) O(lgN) O(lgN) add O(N) O(lgN) O(N) Space used N 9N N Hashing Hash table ADT Hash table data structure: A list of keys and TableSize Hash function: A mapping that map each key into some number in the range 0 to TableSize-1 and distributes the keys evenly among the appropriate cell HashingThe major problems are choosing a function, deciding what to do when two keys hash to the same value (this is known as acollision), and deciding on the table size RehashingIf the table gets too full, the running time for the operations will start taking too long, and insertions might fail for open addressing hashing with quadratic resolution. A solution is to build another table that is about twice as big (with an associated new hash function) and scan down the entire original hash table, computing the new hash value for each (nondeleted) element and inserting it in the new table. The Big-FiveIn C++11, classes come with five special functions that are already written for you. These are the destructor, copy constructor, move constructor, copy assignment operator, and move assignment operator. Collectively these are the big-five. DestructorThe destructor is called whenever an object goes out of scope or is subjected to a delete. Typically, the only responsibility of the destructor is to free up any resources that were acquired during the use of the object. This includes calling delete for any corresponding news, closing any files that were opened, and so on. The default simply applies the destructor on each data member. ConstructorA constructor is a method that describes how an instance of the class is constructed. If no constructor is explicitly defined, one that initializes the data members using language defaults is automatically generated. Copy Constructor and Move Constructor Copy Assignment and Move Assignment (operator=)By Defaults, if a class consists of data members that are exclusively primitive types and objects for which the defaults make sense, the class defaults will usually make sense.The main problem occurs in a class that contains a data member that is a pointer. The default destructor does nothing to data members that are pointers (for good reason—recall that we must delete ourselves). Furthermore, the copy constructor and copy assignment operator both copy the value of the pointer rather than the objects being pointed at. Thus, we will have two class instances that contain pointers that point to the same object. This is a so-called shallow copy (contrast to deep copy). To avoid shallow copy, ban the copy funtionality by calling DISALLOW_COPYING(ClassType). As a result, when a class contains pointers as data members, and deep semantics are important, we typically must implement the destructor, copy assignment, and copy constructors ourselves. Explicit constructor:All one-parameter constructors should be made explicit to avoid behind-the-scenes type conversions. Otherwise, there are somewhat lenient rules that will allow type conversions without explicit casting operations. Usually, this is unwanted behavior that destroys strong typing and can lead to hard-to-find bugs.The use of explicit means that a one-parameter constructor cannot be used to generate an implicit temporary 1234567891011class IntCell &#123;public: explicit IntCell( int initialValue = 0 ) : storedValue&#123; initialValue &#125; &#123; &#125; int read( ) const &#123; return storedValue; &#125;private: int storedValue; &#125;;IntCell obj; // obj is an IntCellobj = 37; // Should not compile: type mismatch Since IntCell constructor is declared explicit, the compiler will correctly complain that there is a type mismatch TemplateType-independentWhen we write C++ code for a type-independent algorithm or data structure, we would prefer to write the code once rather than recode it for each different type Function template A function template is not an actual function, but instead is a pattern for what could become a function. An expansion for each new type generates additional code; this is known as code bloat when it occurs in large projects.Class template12345678template &lt;typename Object&gt;class MemoryCell &#123; public: explicit MemoryCell( const Object &amp; initialValue = Object&#123; &#125; ) : storedValue&#123; initialValue &#125; &#123; &#125; private: Object storedValue;&#125;; MemoryCell is not a class, it is only a class template. It will be a class if specify the Object type. MemoryCell&lt;int&gt; and MemoryCell&lt;string&gt; are the actual classes. Graph AlgorithmsDefinitions: vertices, edges, arcs, directed arcs = digraphs, weight/cost, path, length, acyclic(no cycles) Topological Sort A topological sort is an ordering of vertices in a directed acyclic graph, such that if there is a path from vi to vj, then vj appears after vi in the ordering. A topological ordering is not possible if the graph has a cycle To find a topological ordering, define the indegree of a vertex v as the number of edges (u, v), then use a queue or stack to keep the present 0 indegree vertexes. At each stage, as long as the queue is not empty, dequeue a 0 indegree vertexes in the queue, enqueue each new generated 0 indegree vertexes into the queue. Sortest-Path Algorithms Breadth-first search Explores equally in all directions To find unweighted shortest paths Operates by processing vertices in layers: The vertices closest to the start are evaluated first, and the most distant vertices are evaluated last. Dijkstra’s Algorithm Also called Uniform Cost Search, cost matters Instead of exploring all possible paths equally, it favors lower cost paths. Dijkstra’s algorithm proceeds in stages. At each stage, while there are still vertices waiting to be known: Selects a vertex v, which has the smallest dv among all the unknown vertices, and declares v as known stage. For each of v’s neighbors, w, if the new path’s cost from v to w is better than previous dw, dw will be updated. But w will not be marked as known, unless at next while-loop stage, dw happens to be the smalles. The above steps could be implemented via a priority queue. A proof by contradiction will show that this algorithm always works as long as no edge has a negative cost. If the graph is sparse, with |E| =θ(|V|), this algorithm is too slow. In this case, the distances would need to be kept in a priority queue. Selection of the vertex v is a deleteMin operation. The update of w’s distance can be implemented two ways. One way treats the update as a decreaseKey operation. An alternate method is to insert w and the new value dw into the priority queue every time w’s distance changes. Greedy Best First Search(Heuristic search) With Breadth First Search and Dijkstra’s Algorithm, the frontier expands in all directions. This is a reasonable choice if you’re trying to find a path to all locations or to many locations. However, a common case is to find a path to only one location. A modification of Dijkstra’s Algorithm, optimized for a single destination. It prioritizes paths that seem to be leading closer to the goal. To make the frontier expand towards the goal more than it expands in other directions. First, define a heuristic function that tells us how close we are to the goal, design a heuristic for each type of graph 123def heuristic(a, b): # Manhattan distance on a square grid return abs(a.x - b.x) + abs(a.y - b.y) Use the estimated distance to the goal for the priority queue ordering. The location closest to the goal will be explored first. This algorithm runs faster when there aren’t a lot of obstacles, but the paths aren’t as good(not always the shortest). A* Algorithm Dijkstra’s Algorithm works well to find the shortest path, but it wastes time exploring in directions that aren’t promising. Greedy Best First Search explores in promising directions but it may not find the shortest path. The A* algorithm uses both the actual distance from the start and the estimated distance to the goal. Compare the algorithms: Dijkstra’s Algorithm calculates the distance from the start point. Greedy Best-First Search estimates the distance to the goal point. A* is using the sum of those two distances. So A* is the best of both worlds. As long as the heuristic does not overestimate distances, A* does not use the heuristic to come up with an approximate answer. It finds an optimal path, like Dijkstra’s Algorithm does. A* uses the heuristic to reorder the nodes so that it’s more likely that the goal node will be encountered sooner. Conclusion: Which algorithm should you use for finding paths on a map? If you want to find paths from or to all all locations, use Breadth First Search or Dijkstra’s Algorithm. Use Breadth First Search if movement costs are all the same; use Dijkstra’s Algorithm if movement costs vary. If you want to find paths to one location, use Greedy Best First Search or A*. Prefer A in most cases. When you’re tempted to use Greedy Best First Search, consider using A with an “inadmissible” heuristic. If you want the optimal paths, Breadth First Search and Dijkstra’s Algorithm are guaranteed to find the shortest path given the input graph. Greedy Best First Search is not. A* is guaranteed to find the shortest path if the heuristic is never larger than the true distance. (As the heuristic becomes smaller, A turns into Dijkstra’s Algorithm. As the heuristic becomes larger, A turns into Greedy Best First Search.) Advanced Data StructuresRed-Black TreesRed-black tree leads to a natural implementation of the insertion algorithm for 2-3 trees RBT definition Red-black tree means encoding 2-3 trees in this way: red links, which bind together two 2-nodes to represent 3-nodes, and black links, which bind together the 2-3 tree. An equivalent definition is to define red-black BSTs as BSTs having red and black links and satisfying the following three restrictions: Red links lean left. No node has two red links connected to it. The tree has perfect black balance : every path from the root to a null link has the same number of black links. A 1-1 correspondence: If we draw the red links horizontally in a red-black BST, all of the null links are the same distance from the root, and if we then collapse together the nodes connected by red links, the result is a 2-3 tree. RBT implementaion Color representation: Each node is pointed to by precisely one link from its parent, Encode the color of links in nodes, by adding a boolean instance variable color to our Node data type, which is true if the link from the parent is red and false if it is black. By convention, null links are black. For clarity, define constants RED and BLACK for use in setting and testing this variable. Rotation To correct right-leaning red links or two red links in a row conditions. takes a link to a red-black BST as argument and, assuming that link to be to a Node h whose right link is red, makes the necessary adjustments and returns a link to a node that is the root of a red-black BST for the same set of keys whose left link is red. Actually it is switching from having the smaller of the two keys at the root to having the larger of the two keys at the root. Flipping colors to split a 4-node In addition to flipping the colors of the children from red to black, we also flip the color of the parent from black to red. Keeping the root black. Insertion Maintain the 1-1 correspondence between 2-3 trees and red-black BSTs during insertion by judicious use of three simple operations: left rotate, right rotate, and color flip. If the right child is red and the left child is black, rotate left. If both the left child and its left child are red, rotate right. If both children are red, flip colors. Deletion Assignments Name Hash Game of Life Serafini Recursion Boggle! Patient Queue Huffman Encoding Trailblazer]]></content>
      <categories>
        <category>学习笔记</category>
        <category>计算机科学</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>软件工程</tag>
        <tag>数据结构</tag>
        <tag>算法</tag>
        <tag>C++</tag>
        <tag>cs106b</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法与数据结构 09 - Java | 双向链表 Doubly Linked List - CS61B Berkeley]]></title>
    <url>%2FNOTE-CS61B-data-structures-09-java-doubly-linked-list%2F</url>
    <content type="text"><![CDATA[双向链表 Doubly Linked List前面介绍过单向链表，不过单向链表有几个缺点. 第一个就是它的addLast操作非常慢。单向链表只有一个变量保存列表头的地址, 以及每个节点对后面节点的单向引用(链接). 对于很长的列表，addLast方法必须遍历整个列表, 一直到找到列表末尾才能执行插入操作. 那么如何解决呢? 最直观的解决方案就是加个’车尾’, 如图 这样我们就可以直接通过last.next引用末尾位置.不过另一个问题并没有解决, 就是删除列表最后一项removeLast这个操作还是很慢。因为在目前的结构设计下, 我们需要先找到倒数第二项，然后将其下一个指针设置为null。而要找到倒数第二节点, 我们就得先找到倒数第三个节点…… 以此类推。也就是说，对于删除末尾的操作，还是要几乎遍历整个列表。 反方向的链接基于前面单向链表构建双向链表, 一个比较有效的方法是额外为每个节点添加一个指向前面节点的链接/指针.12345public class OneNode &#123; public OneNode prev; //指向前 public int item; public OneNode next; //指向后&#125; 增加这些额外的指针会导致额外的代码复杂度, 以及额外的内存开销, 这就是追求时间效率的代价. Sentinel 与尾节点双向链表的一个设计初衷，就是为了解决单向链表针对列表末尾位置的操作效率不高的问题，除了sentinel和反方向的链接还不够，我们还需要一个节点（指针）能够直接帮我们定位到列表末端。可以考虑添加一个的尾节点last， 这样的列表就可以支持O(1)复杂度的addLast,getLast 和 removeLast操作了。 循环双端链表上面的尾节点设计虽然没什么错误，但有点瑕疵：最后一个尾节点指针有时指向前哨节点，有时指向一个真正的节点。更好的方法是使双向链表首尾相连, 构成一个循环，即前后节点共享唯一的一个前哨节点。 这样的设计相对更整洁，更美观(主观上的), sentinel的prev就指向列表最后一个节点, sentinel的next指向列表第一个节点.12345678910111213public class LinkedListDeque&lt;GType&gt; &#123; private class OneNode &#123; public OneNode prev; //sentinel's forward link always points to the last element public GType item; public OneNode next; //sentinel's backward link always points to the first element public OneNode(OneNode p, GType i, OneNode n) &#123; prev = p; item = i; next = n; &#125; &#125;&#125; 然后修改构造函数:123456789101112131415/** Creates an empty deque. */public LinkedListDeque()&#123; sentinel = new OneNode(null,null, null); sentinel.prev = sentinel; sentinel.next = sentinel; size = 0;&#125;/** Creates a deque with x */public LinkedListDeque(GType x)&#123; sentinel = new OneNode(null, null, null); sentinel.next = new OneNode(sentinel, x,sentinel); sentinel.prev = sentinel.next; size = 1;&#125; 如果是初始化空列表, 那么其实就是一个自己指向自己的sentinel节点. 如果是非空列表, 那么sentinel节点和真实的节点就构成了一个最简单的二元循环体. 针对列表末尾位置的操作双端链表结构优雅，虽然某些操作如addFirst等编码复杂度会提高, 但不影响速度. 更重要的是, 相比单向链表, 它反而使得addLast, moveLast等方法的代码实现变得简单了, 而且还进一步提升了运行速度(O(n)到O(c)).1234567891011121314151617181920212223/** Adds an item to the back of the Deque. * O(c) */public void addLast(GType x)&#123; OneNode oldBackNode = sentinel.prev; OneNode newNode = new OneNode(oldBackNode, x, sentinel); sentinel.prev = newNode; oldBackNode.next = newNode; size += 1;&#125;/** Removes and returns the item at the front of the Deque. * If no such item exists, returns null.O(c). */public GType removeFirst()&#123; if (isEmpty())&#123; return null; &#125; OneNode oldFrontNode = sentinel.next; sentinel.next = oldFrontNode.next; oldFrontNode.next.prev = sentinel; size -= 1; return oldFrontNode.item;&#125;]]></content>
      <categories>
        <category>学习笔记</category>
        <category>计算机科学</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>Java</tag>
        <tag>软件工程</tag>
        <tag>数据结构</tag>
        <tag>算法</tag>
        <tag>cs61b</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法与数据结构 08 - Java | 单向链表 Singly Linked List - CS61B Berkeley]]></title>
    <url>%2FNOTE-CS61B-data-structures-08-java-singly-linked-list%2F</url>
    <content type="text"><![CDATA[链表 Linked List前面有介绍以array为基础搭建的列表，支持自动扩容, 各种插入，删除速度都很快.这里再介绍另一种方案, 链表, 也可以实现列表自动扩容. 带链接的节点链表的核心组成是带链接的节点, 每个节点就像火车车厢, 有钩子连接下一节车厢. 以int节点为例:123456789public class IntNode &#123; public int item; public IntNode next; public IntNode(int i, IntNode n) &#123; item = i; next = n; &#125;&#125; next就是这个链接, 每一个节点就是其上一个节点的next. 嵌套类 Nested static class这个节点作为一个相对独立的数据结构, 我们更希望让他单独作为一个类来维护. 再另外创建一个名为LinkedList的class与用户进行交互. 这样还有另一个好处就是提供一个命名为LinkedList的类给用户交互，用户更直观地知道自己是在调用链表。如果直接与node类交互，用户可能会困扰. 但同时考虑到这个node类只有LinkedList会调用，所以我们可以把node类嵌套进LinkedList中，也就是嵌套类，在类中定义类。1234567891011121314151617181920public class LinkedList&lt;XXX&gt; &#123; private class OneNode &#123; public XXX item; public OneNode next; public OneNode(XXX i, OneNode n) &#123; item = i; next = n; &#125; &#125; private OneNode first; private int size; public LinkedList(XXX x) &#123; first = new OneNode(x, null); size = 1; &#125; //下面是各种方法...&#125; 以上定义使用了泛型。声明OneNode实例first为私有变量, 是为了防止用户错误地摆弄链接指向，private和public的使用参考. 静态与非静态嵌套类123456789class OuterClass &#123; ... static class StaticNestedClass &#123; ... &#125; class InnerClass &#123; ... &#125;&#125; 如果嵌套类不需要使用LinkedList的任何实例方法或变量，那可以声明嵌套类为static。像静态类方法一样，静态嵌套类不能直接引用其外部类中定义的实例变量或方法, 只能通过实例对象引用来使用它们。同时外部类不能直接访问静态嵌套类的成员变量，但可以通过静态嵌套类来访问。 非静态嵌套类一般叫做内部类inner class。与实例方法和变量一样，内部类与其外部类的实例关联，并且可以直接访问该对象的方法和变量。另外，因为内部类与一个实例相关联，所以它不能自己定义任何静态成员。一个内部类的实例作为成员存在于其外部类的实例中, InnerClass的一个实例只能存在于OuterClass的一个实例中，并且可以直接访问它的外部实例的方法和变量。 作为OuterClass的成员，嵌套类可以声明为private，public，protected或package private。外部类只能声明为public或package private。更多详情参考官网. 补充必要的实例方法插入的操作核心是改变链接指向， 比如原来是A-&gt;B-&gt;D, 要插入C, 则把C.next指向D,然后把B.next改为指向C, 变为A-&gt;B-&gt;C-&gt;D123456789101112131415161718192021222324252627282930313233/** 在列表开头插入 x. */public void addFirst(XXX x) &#123; first = new OneNode(x, first); size += 1;&#125;/** 返回列表第一个元素. */public XXX getFirst() &#123; return first.item; &#125;/** 在列表末尾插入 x. */public void addLast(XXX x) &#123; size += 1; OneNode p = first; /* 把 p 当做指针顺藤摸瓜一直挪到列表末尾. */ while (p.next != null) &#123; p = p.next; &#125; p.next = new OneNode(x, null);&#125;/** 删除列表末尾的元素. */public void removeLast()&#123; //自行补充...&#125;public int size() &#123; return size;&#125; 可以看到，如果用户不小心把某节点x指回自己x.next=x,那就会进入死循环，所以我们需要把OnoNode实例first声明为私有变量已提供必要的保护。 超载 overloading如果想初始化一个空列表, 可以:12345/** 构造一个空列表. */public LinkedList() &#123; fist = null; size = 0;&#125; 即使原来已经有一个带参数x的构造器了, 这里再加一个同名构造器也没问题. 因为Java允许有不同参数的方法重名, 叫超载 overloading. 程序不变条件 invariants上面超载了一个初始化空列表的构造器,加入初始化一个空列表，然后直接调用addLast，程序会报错, 因为null没有next. 有几种修改方法, 比如用if else这种加特例的方法. 这个方案虽然可以能解决问题，但是必要时应该避免加入特例代码, 毕竟有特例就意味着增加了复杂性和额外的代码特例记忆需求, 而人记忆是有限的. 一个更简洁（尽管不太显而易见）的解决方案是修改数据结构本身，让所有LinkedList，维护起来都没有差别，即使是空的。如果把列表比做拉货的火车，那么货物就是列表承载的数据。一列火车如果只有车厢而没有车头（或者车尾）的话是没有意义的，因为没有动力。所以不管火车有没有拉货，有车厢还是没车厢，要称之为火车我们至少需要一个火车头。我们可以通过创建一个特殊节点, 称为前哨节点 sentinel。前哨节点将保存一个值，具体数值我们不关心，它只是作为火车头，不装货。所以我们要修改LinkedList为：12345678910111213141516171819202122/* 第一个元素 （假如有的话）就是 sentinel.next. */public class LinkedList&lt;XXX&gt; &#123; private class OneNode &#123; //... &#125; private OneNode sentinel; private int size; /** 构造一个空列表. */ public LinkedList() &#123; sentinel = new OneNode(null, null); size = 0; &#125; /** 构造一个初始元素为x的列表. */ public LinkedList(XXX x) &#123; sentinel = new OneNode(null, null); sentinel.next = new OneNode(x, null); size = 1; &#125;&#125; 对于像LinkedList这样简单的数据结构来说，特例不多我们也许可以hold住, 一旦后续遇到像树tree等更复杂的数据结构，控制特例数量就显得极为重要了。所以现在就要培养自己的这方面的习惯，保持程序不变条件成立 Invariants。所谓 invariants 就是指数据结构任何情况下都是不会出错（除非程序有bug）. 具有前哨节点的LinkedList至少具有以下 invariants： 列表默认存在前哨节点。 列表第一个元素（如果非空的话）总是在sentinel.next.item。 size变量始终是已添加的元素总数。 不变条件使得代码的推敲变得更加容易，同时给程序员提供了能够确保代码正常工作的具体目标。]]></content>
      <categories>
        <category>学习笔记</category>
        <category>计算机科学</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>Java</tag>
        <tag>软件工程</tag>
        <tag>数据结构</tag>
        <tag>算法</tag>
        <tag>cs61b</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git Bash 直接启动 sublime 或 atom 等编辑器以打开或新建文件]]></title>
    <url>%2FLaunch-editor-in-Gitbash%2F</url>
    <content type="text"><![CDATA[程序员或者其他需要码字多的人，经常要使用编辑器如sublime、atom 和 Typora等。如果每次都要用鼠标点击才能用sublime打开文件，或者在编辑器中新建文件，那么就会有点麻烦！但你可以用一句命令解决！ 配置在Git Bash中用各种文本编辑器打开文件或者直接新建文件。这里以atom为例。 常规步骤 打开Git Bash并cd到你的目标文件夹, 或者直接在目标文件中右键打开Git Bash. atom xxx.md 就会在弹出的atom窗口中打开名为xxx.md的markdown文件, 如果没有这个文件, 会自动创建一个. 适用于其他类型文件, 如.java等. 如果想用sublime, 可以用subl xxx.java, 同理notepad++ 可以用 notepad++ xxx.java等。 (若出现错误,看下面) 若系统无法识别命令一般使用sublime或者notepad++的用户, 可能会出现error: 系统无法识别命令...之类的, 可以这么解决: 方法1新建一个文件命名为subl（注意不能有后缀名），内容：12#!/bin/sh&quot;D:\Sublime Text 3\sublime_text.exe&quot; $1 &amp; 第一行指明这是个 shell 脚本.第二行的字符串是sublime的安装目录, 示例只是我电脑的目录, 注意这里要改为你自己的目录,第二行的$1 是取的命令之后输入的参数第二行的&amp;是此命令在后台打开，这样sublime打开之后，就不会阻塞你的git bash 文件保存到 C:\Program Files (x86)\Git\mingW32\bin 目录下(你的git目录可能与我的不一样，注意改成你自己的) 同理适用于其他编辑器，比如用chrome打开.html文件等。如果不想每次都新建一个文件，可以用下面的方法2。 方法2 找到 C:\Users\你的计算机名目录，如果你的计算机名是Administrator，那么你就要去C:\Users\Administrator目录下, 这里一般存放着windows系统的我的文档, 桌面等文件夹. 在该目录下用Git Bash输入notepad .bashrc, 这会用windows记事本新建并打开一个文件.bashrc，这个文件没有名称只有后缀名。.bashrc里面可以给Git Bash设置命令的别名, 设置路径等。 在.bashrc文件加入下面一行文本alias notepad++=&quot;/D/Notepad++/notepad++.exe&quot;, 这里你需要修改为你电脑的安装路径。alias就是别名的意思，当我们执行notepad++的时候，实际执行的是=后面的语句. 重新打开Git Bash, 设置才能生效，如果不想关掉在打开的话，可以直接在bash下输入source ~/.bashrc就可以立刻加载修改后的设置，设置立即生效。现在在bash下输入notepad++ test.py, 就直接打开了notepad++并创建了这个叫test的Python文件。这里的别名不一定非要取notepad++，随你想叫什么都行。 同理也可以扩展到别的文本编辑器，alias atom=&quot;atom的路径&quot;, alias sublime=&quot;sublime的路径&quot;等. 最后还要注意一点，上面所说的路径最好不要有空格，括号等，否则会造成命令无效. .bashrc还有很多有用的配置,可以根据需要进行扩展. 比如很多程序猿会选择修改删除命令rm(此命令不加任何参数的话，会直接删除文件, 可能会造成误删的后果)。这个时候可以给rm加个参数-i，意为在删除的时候给出提示。在文件.bashrc里添加这行代码alias rm=&quot;rm -i&quot;。但这里不建议这么做，因为rm=&quot;rm -i&quot;是一个定时炸弹，在使用它之后，习惯了之后, 你会本能地期望rm在删除文件之前会提示你。但是，总有一天你可能会用一个没有rm alias 别名的系统, 这时若你也直接随手一甩rm, 本以为会有提示, 结果发现数据真的被删除了。 在任何情况下，预防文件丢失或损坏的好方法就是进行备份。 所以如果你想个性化删除命令, 最好不要动rm，而是创建属于你的命令，比如trash, myrm, delete等, 用alias trash=&#39;/bin/rm -irv&#39;会创建一条把文件放入垃圾回收站的命令.]]></content>
      <categories>
        <category>提高效率</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>软件工程</tag>
        <tag>Sublime</tag>
        <tag>Atom</tag>
        <tag>编辑器</tag>
        <tag>Git Bash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法与数据结构 07 - Java | 用数组构建数据列表 list - CS61B Berkeley]]></title>
    <url>%2FNOTE-CS61B-data-structures-07-java-array-based-list%2F</url>
    <content type="text"><![CDATA[列表 List前面说到Java的数组无法更改长度，那么也就无法实现插入或者删除数组成员。Java提供了功能更丰富的数据结构 - 列表（list）。所谓列表，即有序的集合（序列），用户可以精确地控制每个元素插入到列表中的哪个位置。用户可以通过整数索引（列表中的位置）来访问元素，并搜索列表中的元素（详细可进一步参考oracle官网）。 这里我们尝试以java的array为基础实现一个列表，目标是实现自动扩容 (Java中的ArrayList不仅仅有自动扩容, 也继承了[List]的其他功能)。在探索的过程中, 可以顺带学习很多相关的内容.使用自上而下的设计思想搭建一个框架:先写出最基础的部分, 也就是一个构造器，前面学过了整数数组，我们直接拿来用123456789101112131415161718/** Array based list. */// index 0 1 2 3 4 5 6 7// items: [6 9 -1 2 0 0 0 0 ...]// size: 5public class AList &#123; private int[] items; private int size; /** 构造一个初始容量100的数组，初始有效数据成员为0. */ public AList() &#123; items = new int[100]; size = 0; &#125; /** 下面添加其他方法 */&#125; 然后思考我们需要什么功能，把功能需求转化为实例方法instance method的形式，先把方法的外壳描绘出来，注释上该方法的功能（目的），输入值，返回值是什么之类的。具体的功能实现可以先空着，之后一步步丰富。 公共 vs 私有 Public vs. Private在上面的代码块中，可以看到 items 和 size 都被声明为 private 私有变量, 这样就只能被所在的java文件内调用. 私有变量和方法的设计初衷是服务于程序的内部功能实现, 而不是用来和外部程序(用户)进行交互的. 设置成私有, 可以避免这些变量和方法被外部程序直接调用, 避免用户通过不恰当/容易出错的方式修改某些变量. 在程序说明文档中, 一般也会明确说明程序提供什么公共变量和方法给用户调用. 因此我们这里也提供几个 public 方法让用户调用, 这样用户就能按照我们设计的方式来访问数据。分别是getLast() - 访问列表最后一个元素，get(int i)访问第i个元素, 和size()访问列表的大小.12345678910111213141516/** 程序内的方法可以访问 private 变量 *//** 返回列表末尾的值. */public int getLast() &#123; return items[size - 1];&#125;/** 返回第 i 个值 (0 是第一个). */public int get(int i) &#123; return items[i];&#125;/** 返回列表元素长度. */public int size() &#123; return size;&#125; 泛型数组我们不仅希望我们的列表可以存整数，也可以存其他类型的数据，可以通过泛型解决，泛型的介绍参考这篇文章. 泛型数组跟前面介绍的泛型示例有一个重要的语法差异：Java不允许我们创建一个通用对象的数组，原因这里不细展开。 假如我们用Item来标识泛型, 那么在上面的列表类中构建泛型数组时, 我们不能用items = new Item[8];, 而要用items = (Item []) new Object[8];, 即使这样也会产生一个编译警告，但先忍着, 后面会更详细地讨论这个问题。12345678910public class AList&lt;Item&gt; &#123; private Item[] items; private int size; /** 构造一个初始容量100的数组，初始有效数据成员为0. */ public AList() &#123; items = (Item[]) new Object[100]; //会有编译警告, 暂时不管, 后面会解释 size = 0; &#125;&#125; 数组扩容 Resize一个列表应该支持基本的插入和删除数据的操作，但是因为数组本身无法更改长度，所以我们就需要一个方法，在给数组在插入新数据时，先检查长度容量是否足够，如果不够，那么就要增加长度。我们考虑简单的情况, 即需要在数组末尾插入或者删除数据怎么办 插入元素：123456789101112/** 把 X 插入到列表末尾. */public void addLast(Item x) &#123; /** 检查长度容量是否足够，如果不够，那么就要增加长度 */ if (size == items.length) &#123; Item[] temp = (Item[]) new Object[size + 1]; System.arraycopy(items, 0, temp, 0, size); items = temp; &#125; items[size] = x; size = size + 1;&#125; 创建新array并把旧数据复制过去的过程通常称为“resizing”。其实用词不当，因为数组实际上并没有改变大小，只是把小数组上的数据复制到大数组上而已。 为了让代码更易于维护，可以把上面的代码中负责大小调整的部分包装在一个独立的method中123456789101112131415161718192021222324252627/** 改变列表容量, capacity为改变后的容量. */private void resize(int capacity) &#123; Item[] temp = (Item[]) new Object[capacity]; System.arraycopy(items, 0, temp, 0, size); items = temp;&#125;/** 把 X 插入到列表末尾. */public void addLast(Item x) &#123; if (size == items.length) &#123; resize(size + 1); &#125; items[size] = x; size = size + 1;&#125;``` 删除元素：```java/** 删去列表最后一个值，并返回该值 */public int removeLast() &#123; Item x = getLast(); items[size - 1] = null; // 曾经引用“删除”的元素的内存地址被清空 size = size - 1; return x;&#125; 事实上即使没有items[size - 1] = null;,也可以达到删除元素的目的.删除对改存储的对象的引用, 是为了避免“loitering”。所谓 loitering，可以理解为占着茅坑不拉屎的对象，它们已经没啥用了，却还是占用着内存。如果这个对象是些几十兆的高清图片，那么就会很消耗内存。这也是为什么安卓手机越用越慢的一个原因。 当引用/内存地址丢失时，Java会销毁对象。如果我们不清空引用，那么Java将不会垃圾回收这些本来预计要删除的对象, 因为它们实际还被列表引用着。 扩容效率分析我们直觉也会感觉到，如果按照现在的设计，即每插入一个新元素，就重新复制一遍数组，这样随着数组越来越大，效率肯定会越来越差。事实上也是这样，如果数组目前长度是100个内存块，那么插入1000次，需要创建并填充大约50万个内存块（等差数列求和N(N+1)/2，101+102+…+1000 ≈ 500000）。但假如我们第一次就扩容到1000，那么就省却了很多运算消耗。可惜我们不知道用户需要插入多少数据，所以要采取其他方法-几何调整。也就是与其按照size + FACTOR这样的速率增加容量, 不如按照size * RFACTOR成倍扩容, 前者的增加速率为1, 后者为 RFACTOR, 只要设置 RFACTOR 大于1, 就能减少扩容的次数.123456789/** 把 X 插入到列表末尾. */public void addLast(Item x) &#123; if (size == items.length) &#123; resize(size * RFACTOR); //用 RFACTOR 作为因子扩容数组, &#125; items[size] = x; size = size + 1;&#125; 目前我们解决了时间效率问题, 但代价是需要更大的内存空间, 也就是空间效率下降了. 假设我们插入了十亿个item，然后再删去九亿九千万个项目。在这种情况下，我们将只使用10,000,000个内存块，剩下99％完全没有使用到。 为了解决这个问题，我们可以在数组容量利用率比较低时把容量降下来. 定义利用率 R 为列表的大小除以items数组的长度。一般当R下降到小于0.25时，我们将数组的大小减半。 其他功能比如排序等, 在后面介绍链表的文章中再讨论.]]></content>
      <categories>
        <category>学习笔记</category>
        <category>计算机科学</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>Java</tag>
        <tag>软件工程</tag>
        <tag>数据结构</tag>
        <tag>算法</tag>
        <tag>cs61b</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法与数据结构 06 - Java | array 数组 - CS61B Berkeley]]></title>
    <url>%2FNOTE-CS61B-data-structures-06-java-array%2F</url>
    <content type="text"><![CDATA[数组 Array数组是一种特殊的对象，有一个固定的数组长度参数N，由一连串（N个）连续的带编号的内存块组成，每个都是相同的类型(不像Python可以包含不同类型)，索引从0到N-1编号。A[i]获得数组A的第i个元素。这与普通的类实例不同，类实例有具体变量名命名的内存块。 数组实例化，包含对象的数组 Array Instantiation, Arrays of Objects要创建最简单的整数数组, 有三种方式:123x = new int [3]; //创建一个指定长度的数组，并用默认值（0）填充每个内存块。y = new int [] &#123;1，2，3，4，5&#125;; //创建一个合适大小的数组，以容纳指定的初始值int [] z = &#123;9，10，11，12，13&#125;; //省略了new，只能结合变量声明使用。 创建一组实例化对象:12345678910public class DogArrayDemo &#123; public static void main(String[] args) &#123; /* Create an array of two dogs. */ Dog[] dogs = new Dog[2]; dogs[0] = new Dog(8); dogs[1] = new Dog(20); /* Yipping will result, since dogs[0] has weight 8. */ dogs[0].makeNoise(); &#125;&#125; 注意到new有两种不同的使用方式：一种是创建一个可以容纳两个Dog对象的数组，另外两个创建各个实际的Dog实例。 数组复制123x = new int[]&#123;-1, 2, 5, 4, 99&#125;;int[] b = &#123;9, 10, 11&#125;;System.arraycopy(b, 0, x, 3, 2); //效果类似于Python的`x[3:5] = b[0:2]` System.arraycopy的五个参数分别代表： 待复制的数组(源) 源数组复制起点 目标数组 目标数组粘贴起点 有多少项要复制 2D数组Java的二维数组实质上是一数组的数组, 即每一个数组元素里面也是一个数组。1234567891011121314151617int[][] matrix; //声明一个引用数组的数组matrix = new int[4][]; //创建四个内存块, 用默认null值填充, 之后用于储存对整数数组的引用, 即地址,int[] rowZero = matrix[0];/** 实例化整数数组, 把其地址/引用分别赋值给/储存到 matrix 的第N个内存块*/matrix[0] = new int[]&#123;1&#125;;matrix[1] = new int[]&#123;1, 1&#125;;matrix[2] = new int[]&#123;1, 2, 1&#125;;matrix[3] = new int[]&#123;1, 3, 3, 1&#125;;int[] rowTwo = matrix[2];rowTwo[1] = -5;/** 创建四个内存块, 其中每个被引用的整数数组长度为4,每个元素都是0.*/matrix = new int[4][4];int[][] matrixAgain = new int[][]&#123;&#123;1&#125;, &#123;1, 1&#125;,&#123;1, 2, 1&#125;, &#123;1, 3, 3, 1&#125;&#125;;]]></content>
      <categories>
        <category>学习笔记</category>
        <category>计算机科学</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>Java</tag>
        <tag>软件工程</tag>
        <tag>数据结构</tag>
        <tag>算法</tag>
        <tag>cs61b</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法与数据结构 05 - Java | 数据类型 - CS61B Berkeley]]></title>
    <url>%2FNOTE-CS61B-data-structures-05-java-variable-types%2F</url>
    <content type="text"><![CDATA[数据类型数据类型是程序设计语言描述事物、对象的方法。Java数据类型分为基本类型（内置类型）和引用类型(扩展类型）两大类。基本类型就是Java语言本身提供的基本数据类型，比如，整型数，浮点数，字符，布尔值等等。而引用类型则是Java语言根据基本类型扩展出的其他类型，Java要求所有的引用扩展类型都必须包括在类定义里面，这就是Java为什么是面向对象编程语言的原因… 上面的定义有点抽象，要理解数据类型，需要先理解一个问题: 神秘的海象问题12345678/** 尝试预测下面的代码运行时会发生什么。b的变化是否会影响a？提示：类似Python。 */Walrus a = new Walrus(1000, 8.3);Walrus b;b = a;b.weight = 5;System.out.println(a);System.out.println(b); 12345678/** 同样尝试预测下面的代码运行时会发生什么。x的改变是否影响y？ */int x = 5;int y;y = x;x = 2;System.out.println("x is: " + x);System.out.println("y is: " + y); 首先给出答案, b的变化会影响a, 但x的改变不影响y，具体见可视化过程.这里的差别虽然微妙, 但其背后的原理对于数据结构的效率来说是非常重要的，对这个问题的深入理解也将引导我们写出更安全，更可靠的代码。 基本类型 Primative Types计算机中的所有信息都以一系列1和0的形式存储在内存中，这些二进制的0和1就是比特位（bits）。比如72和“H”在内存一般以01001000的形式存储，对他们的形式是一样的。一个引申问题就是：Java代码如何解释01001000，怎么知道应该解释为72还是“H”？ 通过类型types，预先定义好类型即可, 以下代码1234char x = 'H';int y = x;System.out.println(x);System.out.println(y); 会分别得到“H”和72. 在这种情况下，x和y变量都包含几乎相同的bits，但是Java解释器在输出时对它们进行了不同的处理。 Java有8种基本类型：byte，short，int，long，float，double，boolean和char。 变量声明 Declaring Variables计算机的内存可以视为包含大量用于存储信息的内存比特位，每个位都有一个唯一的地址。现代计算机可以使用许多这样的位。 当你声明一个特定类型的变量时，Java会用一串连续的内存位存储它。例如，如果你声明一个int，你会得到一个长度32的内存list，里面有32bits。Java中的每个数据类型都有不同的比特数。 除了留出内存空间外，Java解释器还会在一个内部表中创建一个条目，将每个变量名称映射到内存块中第一个位置（表头list head）。 例如，如果声明了int x和double y，那么Java可能会决定使用计算机内存的352到384位来存储x，而20800到20864位则用来存储y。然后解释器将记录int x从352开始，y从20800开始。 在Java语言里无法知道变量的具体内存位置，例如你不能以某种方式发现x在位置352。不像C++这样的语言，可以获取一段数据的确切地址。Java的这个特性是一个折衷！隐藏内存位置自然意味着程序猿的控制权更少，就无法做某些类型的优化。但是，它也避免了一大类非常棘手的编程错误。在现在计算成本如此低廉的时代，不成熟的优化还不如少点bug。 当声明一个变量时，Java不会在预留的内存位置中写入任何内容, 也即没有默认值。因此，如果没有赋值, Java编译器会阻止你使用变量。 以上只是内存分配的简要说明, 堆和栈的介绍可以参考我的CS106B C++笔记。 引用类型 Reference Types所有基本数据类型之外的类型都是引用类型。引用类型顾名思义，就是对对象的引用。在java中内存位置是不开放给程序员的, 但我们可以通过引用类型访问内存中某处对象。所有引用类型都是 java.lang.Object 类型的子类。 对象实例化 Object Instantiation对象实例化：当我们使用new（例 new Dog）实例化对象时，Java首先为类的每个实例变量分配一串长度合适的bits位，并用缺省值填充它们。然后，构造函数通常（但不总是）用其他值填充每个位置.123456789public static class Walrus &#123; public int weight; public double tuskSize; public Walrus(int w, double ts) &#123; weight = w; tuskSize = ts; &#125;&#125; 用new Walrus(1000, 8.3)创建一个Walrus实例后, 我们得到分别由一个32位(int weight = 1000)和一个64位(double tuskSize = 8.3)的内存块组成的实例：通过程序可视化过程)来更好地理解. 当然在Java编程语言的实际实现中，实例化对象时都有一些额外的内存开销, 这里不展开. 通过 new 实例化对象，new 会返回该对象的内存地址给我们，但假如我们没有用一个变量去接收这个地址，那么我们就无法访问这个对象。之后该对象会被作为垃圾回收。 引用变量声明 Reference Variable Declaration前面有提到，我们需要声明变量来接受实例化的对象在内存中的地址。当声明任何引用类型的变量（比如array, 前面的Dog类等）时，Java都会分配一串64位的内存位置. 这个64位的内存块仅用于记录变量的内存地址, 所谓内存地址, 可以理解为内存(房子)的编号(地址), 一般是内存块的表头位置的64位表达式1234Walrus someWalrus; // 创建一个64位的内存位置someWalrus = new Walrus(1000, 8.3); //创建一个新的实例/** 内存地址由 new 返回, 并被复制/赋值给 someWalrus 对应的内存位置*/ 比如, 假设weight是从内存位5051956592385990207开始存储的，后面连续跟着其他实例变量，那么就可以把5051956592385990207存储在Dog变量中。5051956592385990207由64位的二进制0100011000011100001001111100000100011101110111000001111000111111表达，这样smallDog的内存就可以抽象的理解为一个表smallDog: 0100011000011100001001111100000100011101110111000001111000111111 -&gt; 具体存放实例的内存(Walrus: weight=1000, tuskSize=8.3)‘-&gt;’可以理解为指针. 实例化数组在前面有介绍过，数组array是引用类型，是对象，故数组变量只是存储内存位置。 前面有提到，如果丢失了引用变量存储的内存地址，那么该地址对应的对象就找不回来了。例如，如果一个特定的 Walrus 地址的唯一副本存储在x中，那么x = null这行代码将删去地址，我们则丢失了这个 Walrus 对象。这也不一定是坏事，很多时候在完成了一个对象后就不在需要了，只需简单地丢弃这个参考地址就可以了。 Java 等值规则 Rule of Equals对于y = x，Java解释器会将x的位拷贝到y中,这个规则适用于java中任何使用=赋值的语法, 是理解开头的”神秘的海象”问题的关键. 基本类型变量的位, 存储赋值的值（基本类型）在内存中值(具体位数取决于具体的类型) 1234int x = 5; // 此时是把内存中的某一个地址 p 复制给 xint y;y = x; // y 也指向 px = 2; // 把一个新的内存地址 new p 复制给x, 但y还是指向原来的p x的位存储的是基本类型int 5(32 bits), x = 2是把新的基本类型int 2复制给x, 但y还是指向原来的int 5， 所以y没变化。 引用类型 reference type 变量的位, 存储赋值的值（引用类型）在内存中的地址(固定的64 bits) 1234Dog a = new Dog(5); // 创建一个64位的内存位, 并赋值一个新的实例 pDog b; // 仅创建一个64位的内存位, 没有引用内存地址(null)b = a; // 把a的位（是实例 p 的内存地址）复制给b, 这样 b 也是指向实例 pb.weight = 21; // 此时修改b, 会改写b指向的内存实例 p a和b只存储地址, 而它们的地址都指向相同的实例； 如果对 b 的修改本质是对 p的修改, 那么输出a.weight的时候, 就会变成21. 参数传递 Parameter Passing给函数传递参数，本质上也是赋值操作，参考上面的等值规则，也即复制这些参数的bits给函数，也称之为pass by value。Java的参数传递都是pass by value。至于传递过去的参数会不会因为函数内部的操作而更改，其判断原理在上面的等值规则已经阐明。 通用数据类型 Generic在定义类的时候，有时候我们可能希望这个类能够接受任何类型的数据，而不仅仅是限定了基本类型中的任何一种。比如我们想实现一个类似PPT的类，自然需要这个PPT类能够接收各种类型的字符，数字，并呈现出来。这个时候就需要使用泛型 Generic, 也即通用数据类型。 在2004年，Java的设计者在语言中加入了泛型，使​​我们能够创建包含任何引用类型的数据结构（引用类型和基本类型的解释参考另一篇文章, ）。方法就是在类声明的类名后面，使用一个任意的占位符，并用尖括号括住&lt;随便什么字符&gt;。然后，在任何你想使用泛型的地方，改用占位符。比如1234567public class PPT &#123; public class PPT &#123; public int item; ... &#125; ...&#125; 改为1234567public class PPT&lt;xxx&gt; &#123; public class PPT &#123; public xxx item; ... &#125; ...&#125; &lt;xxx&gt;里面的名称并不重要, 改成其他也行, 只是一个标识符, 用来接受参数, 当用户实例化这个类时, 必须使用特殊的语法PPT&lt;String&gt; d = new PPT&lt;&gt;(&quot;hello&quot;); 由于泛型仅适用于引用类型，因此我们不能将基本类型int等放在尖括号内。相反，我们使用基本类型的引用版本，比如对于int, 用 Integer，PPT&lt;Integer&gt; d = new PPT&lt;&gt;(&quot;10&quot;); 总结使用方法: 在一个实现某数据结构的.java文件中，在类名后面, 只指定泛型类型一次。 在其他使用该数据结构的java文件中，声明实例变量时要指定所需的类型。 如果您需要在基本类型上实例化泛型，请使用Integer, Double, Character, Boolean, Long, Short, Byte, Float，而不是其基本类型。]]></content>
      <categories>
        <category>学习笔记</category>
        <category>计算机科学</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>Java</tag>
        <tag>软件工程</tag>
        <tag>数据结构</tag>
        <tag>算法</tag>
        <tag>cs61b</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法与数据结构 04 - Java | 类 class 02 类与实例 - CS61B Berkeley]]></title>
    <url>%2FNOTE-CS61B-data-structures-04-java-class-02-class-instance%2F</url>
    <content type="text"><![CDATA[Class前面提到，类的方法和变量细分为静态的和非静态的. 静态就是可以被类调用，所以静态方法/变量也称之为类方法/变量；非静态只能由实例调用，所以也称之为实例方法/变量。 类方法 vs 实例方法 Class Methods vs. Instance Methods参考上一篇文章的例子，类方法由类调用Dog.makeNoise();. 实例方法只能由实例调用bigDog.makeNoise();. 同理可推, 类方法无法调用实例变量. 可以看到实例方法更具体, 更贴近实体世界, 那我们仍需要类方法, 因为: 有些类不需要实例化, 毕竟我们也经常需要处理抽象的概念, 这些抽象概念在人类认知范畴内是统一的, 比如数学计算, 我们需要计算某个数值的平方根, x = Math.sqrt(100);, 拿来就用, 不需要先实例化. 这点在Python中体现得很好. 有些类有静态方法, 是有实际作用的。例如，若想比较一个类里面的不同实例, 比如两只狗的重量。比较简单的方法就是使用一个比较狗的重量的类方法: 123456789public static Dog maxDog(Dog d1, Dog d2) &#123; if (d1.weight &gt; d2.weight) &#123; return d1; &#125; return d2;&#125;Dog d = new Dog(15);Dog d2 = new Dog(100);Dog.maxDog(d, d2); 这个时候, 若使用实例方法也可以, 但没那么直观：12345678910/** 我们使用关键字this来引用当前对象d。*/public Dog maxDog(Dog d2) &#123; if (this.weight &gt; d2.weight) &#123; return this; &#125; return d2;&#125;Dog d = new Dog(15);Dog d2 = new Dog(100);d.maxDog(d, d2); 类变量 vs 实例变量 Class Variables vs. Instance Variables静态变量的也是有用处的。这些变量一般是类本身固有的属性。例如，我们可能需要用狗类的另一种生物学的统称“犬科”来作为类的说明， 这个时候可以用public static String binomen = &quot;犬科&quot;;，这个变量理论上是由类来访问的。虽然Java在技术上允许使用实例名称来访问静态变量，但是这有时候可能会令人困惑， 所以还是少用为好。 构造器 Constructors in Java与上面的DogLauncher实例化对象的方式相比, 我们更希望实例化可以带参数的，那样可以为我们节省手动给实例变量赋值的麻烦。为了启用这样的语法，我们只需把如下的构造函数直接添加进Dog类中：12345/**注意：构造函数与class类同名 */public Dog(int w) &#123; weight = w; &#125; 然后在DogLauncher里实例化一只狗时, 直接Dog d = new Dog(20);即可. 在以上代码的基础上, 后续当我们想使用new和参数创建一只狗时，可以随时调用public Dog(int w)构造函数。对于熟悉Python的人来说，你可以理解java的构造函数为Python的__init__。 一些术语: 声明(declaration): Dog smalldog;声明一个类作为一个变量在内存中占位 实例化: new Dog(20), 如果没有把它作为值赋给一个类声明变量,那么这个实例化的值会被垃圾回收. 声明, 实例化并赋值: Dog smalldog = new Dog(5)]]></content>
      <categories>
        <category>学习笔记</category>
        <category>计算机科学</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>Java</tag>
        <tag>软件工程</tag>
        <tag>数据结构</tag>
        <tag>算法</tag>
        <tag>cs61b</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法与数据结构 04 - Java | 类 class 01 变量和方法 - CS61B Berkeley]]></title>
    <url>%2FNOTE-CS61B-data-structures-04-java-class-01-intro%2F</url>
    <content type="text"><![CDATA[ClassJava的语法是为了更容易地模拟真实世界而设计的. 比如用程序实现一只狗, 可以用定义一个类class来描述它. 类class里面包括变量Variable，方法method（可以理解为Python的函数function）。变量可以储存数据，方法可以处理数据。变量必须在类中声明(即不能离开类独立存在)，不像Python或Matlab这样的语言可以在运行时添加新的变量。类的方法和变量又细分为静态的和非静态的. 静态就是可以被类调用，所以静态方法/变量也称之为类方法/变量；非静态只能由实例调用，所以也称之为实例方法/变量。实例instance的概念后面会解释。 类（静态）变量和方法 Class(Static) Variables and Methods静态变量和方法的特征就是有static字符在前面.以下代码定义了一个类来模拟狗，包含一个类变量作为这个类的说明，一个类方法用于发出叫声：12345678public class Dog &#123; public static String instruction = "狗类实例"; //类变量, 说明 public static void makeNoise() &#123; System.out.println("汪!"); &#125;&#125; 这里没有定义main(), 在这种情况下如何直接运行这个类(java Dog), 程序是会报错的123错误: 在类 Dog 中找不到 main 方法, 请将 main 方法定义为: public static void main(String[] args)否则 JavaFX 应用程序类必须扩展javafx.application.Application`. 你可以选择在里面添加一个main()方法. 但这次我们选择不定义具体的main(). 具体要如何运行, 我们可以另写一个类定义一个main()方法来调用这个类.12345public class DogLauncher &#123; public static void main(String[] args) &#123; Dog.makeNoise(); &#125;&#125; 这两种方式(在类A内部定义好main() vs. 在其他类B定义main()来调用A)没有优劣之分, 二者有不同的适用情况. 随着不断深入学习，二者的区分将变得更清晰。 注意到, 类变量和方法是有局限性的。现实世界中, 并不是所有的狗都是一样的特征，仅仅靠类这个概念是无法区分不同个体的狗, 除非你为不同的狗定义不同的类（以及里面的变量和方法）, 那么就会很繁琐痛苦. 也就是说，用类来模拟个体是低效的，我们要使用实例. 实例变量和对象实例化 Instance Variables and Object Instantiation Java的类定义就像定义一张蓝图, 我们可以在这个蓝图的基础上, 生成不同的实例instance. 实例是概念性的说法，本质上在Java里就是对象object。这样的特性提供了一个很自然而然地在java中模拟生成实体世界的方法：定义一个狗的类，在这个类的基础上，通过不同的特征参数实例化不同特征的狗（instances），并使类方法的输出取决于特定实例的狗的属性。1234567891011121314/** 一只狗的类:*/public class Dog &#123; public int weight; public void makeNoise() &#123; if (weight &lt; 10) &#123; System.out.println("嘤嘤嘤!"); &#125; else if (weight &lt; 30) &#123; System.out.println("汪汪汪"); &#125; else &#123; System.out.println("嗷呜!"); &#125; &#125; &#125; 这里的方法和变量没有static, 所以是实例（非静态）方法和变量. 如果直接用 Dog 类来调用这些方法, 会报错:123456public class DogLauncher &#123; public static void main(String[] args) &#123; Dog.weight = 21; Dog.makeNoise(); &#125;&#125; 123456DogLauncher.java:3: 错误: 无法从静态上下文中引用非静态 变量 weight Dog.weight = 21; ^DogLauncher.java:4: 错误: 无法从静态上下文中引用非静态 方法 makeNoise() Dog.makeNoise(); ^ 这个时候, 你需要实例化一只狗, 让这个实例来调用非静态变量和方法:1234567public class DogLauncher &#123; public static void main(String[] args) &#123; Dog biglDog = new Dog(); biglDog.weight = 5; biglDog.makeNoise(); &#125;&#125; 运行时，这个程序将会创建一个重量为5的狗，这个狗就会“嗷呜”叫。 总的来说，之所以需要实例方法和变量，是因为我们需要模拟个体，一只具体的狗，并让它发出声音。这个weight和makeNoise()只能由具体的狗调用。狗类不能调用，也没有调用的意义, 毕竟每只狗的重量和声音都不同的. 在设计程序时, 如果其中一个方法我们只打算让特定的实例来调用它(而不让类去调用它), 那么这个方法应该设计成实例方法。]]></content>
      <categories>
        <category>学习笔记</category>
        <category>计算机科学</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>Java</tag>
        <tag>软件工程</tag>
        <tag>数据结构</tag>
        <tag>算法</tag>
        <tag>cs61b</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法与数据结构 03 - Java | 代码风格 注释 Javadoc - CS61B Berkeley]]></title>
    <url>%2FNOTE-CS61B-data-structures-03-java-code-style-comments%2F</url>
    <content type="text"><![CDATA[代码风格与注释 Code style and comments在学习和实践过程中，我们应该努力保持代码可读性。良好的编码风格的一些最重要的特点是： 一致的风格（间距，变量命名，缩进风格等） 大小（线不太宽，源文件不要太长） 描述性命名（变量，函数，类），例如变量或函数名称为年份或getUserName而不是x或f。让代码本身提供可解读性。 避免重复的代码：几乎不会有两个重要的代码块几乎相同，除了一些改变。 适当的评论, 使其他读者也能轻松理解你的代码 行注释: //分隔符开头行被当做注释。 Block（又名多行注释）注释: /*, */, 但我们更推荐javadoc形式的注释。 JavadocJavadoc: / **，*/, 可以（但不总是）包含描述性标签。 借助javadoc工具可以生成HTML格式的API文档。第一段是方法的描述。描述下面是不同的描述性标签, 比如参数 @param， 返回值 @return， 可能抛出的任何异常 @throws123456789/** * @author 名字，邮箱&lt;address @ example.com&gt; * @version 1.6 版本 * @param * @return */public class Test &#123; // class body&#125;]]></content>
      <categories>
        <category>学习笔记</category>
        <category>计算机科学</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>Java</tag>
        <tag>软件工程</tag>
        <tag>数据结构</tag>
        <tag>算法</tag>
        <tag>cs61b</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法与数据结构 02 - Java | 语法基础 - CS61B Berkeley]]></title>
    <url>%2FNOTE-CS61B-data-structures-02-java-basic-syntax%2F</url>
    <content type="text"><![CDATA[Java基本语法12345public class HelloWorld &#123; public static void main(String[] args) &#123; System.out.println("Hello world!"); &#125;&#125; 上面的程序由一个类声明组成，该声明使用关键字public class声明。 Java所有的代码都应该包含在class里面。 真正负责运行的代码，是一个名为main的method，它声明为public static void main(String[] args)。 public：公共的，大部分方法都是以这个关键字开始的，后面会进一步解释。 static：这是一个静态方法，不与任何特定的实例关联，后面会解释。 void：它没有返回类型。 main：这是方法的名称。 String [] args：这是传递给main方法的参数。 使用大括号{ }来表示一段代码的开始和结束。 声明必须以分号结尾 静态分类 Static Typing程序语言静态与动态的分类，可以参考oracle的说明文件，它解释了动态和静态类型之间的区别, 帮助你理解由程序的错误提示信息。两个主要区别:1. 动态类型语言在运行时执行类型检查，而静态类型语言在编译时执行类型检查。这意味如果以静态类型语言（如Java）编写的脚本包含错误，则在编译错误之前将无法编译. 而用动态类型语言编写的脚本可以编译，即使它们包含会阻止脚本正常运行（如果有的话）的错误。2. 静态类型语言要求你在使用它们之前声明变量的数据类型，而动态类型语言则不需要。考虑以下两个代码示例：123// Javaint num;num = 5; 12# Pythonnum = 5 这两段代码都创建一个名为num的变量并赋值为5. 不同之处在于Java需要将num的数据类型明确定义为int。因为Java是静态类型的，因此它期望变量在被赋值之前被声明。 Python是动态类型的，不需要定义类型, Python根据变量的值确定其数据类型。动态类型语言更加灵活，在编写脚本时可以节省时间和空间。但是，这可能会导致运行时出现问题。例如：123# pythonnumber = 5numbr = (number + 15) / 2 #注意错字 上面的代码本应创建一个值为5的可变数字，然后将其加上15并除以2以得到10. 但是，number在第二行的开头拼写错误。由于Python不需要声明变量，因此会不由分说直接创建一个名为numbr的新变量，并把本应分配给number的值分配给它。这段代码会很顺利编译，但是如果程序试图用number来做某事，程序员假设它的值是10，那么后续就无法产生期望的结果,而且还很难注意到问题。 Java的compiler其中一个关键作用是进行静态类型检查（static type check）。若前面定义了 int x = 0;, 那么后面若给x赋值其他的类型值x = &#39;horse&#39;;, compiler就会报错. 这样就保证了程序不会出现类型错误. 除了错误检查外, static types 也可以让程序媛/猿知道自己处的是什么对象. 总而言之，静态类型具有以下优点： 编译器确保所有类型都是兼容的，这使得程序员更容易调试他们的代码。 由于代码保证没有类型错误，所以编译后程序的用户将永远不会遇到类型错误。例如，Android应用程序是用Java编写的，通常仅以.class文件的形式分发，即以编译的格式。因此，这样的应用程序不应该由于类型错误而崩溃。 每个变量，参数和函数都有一个声明的类型，使程序员更容易理解和推理代码。 Code Style, Comments, Javadoc在学习和实践过程中，我们应该努力保持代码可读性。良好的编码风格的一些最重要的特点是： 一致的风格（间距，变量命名，缩进风格等） 大小（线不太宽，源文件不要太长） 描述性命名（变量，函数，类），例如变量或函数名称为年份或getUserName而不是x或f。让代码本身提供可解读性。 避免重复的代码：几乎不会有两个重要的代码块几乎相同，除了一些改变。 适当的评论, 使其他读者也能轻松理解你的代码 行注释: //分隔符开头行被当做注释。 Block（又名多行注释）注释: /*, */, 但我们更推荐javadoc形式的注释。 Javadoc: / **，*/, 可以（但不总是）包含描述性标签。 借助javadoc工具可以生成HTML格式的API文档。第一段是方法的描述。描述下面是不同的描述性标签, 比如参数 @param， 返回值 @return， 可能抛出的任何异常 @throws123456789/** * @author 名字，邮箱&lt;address @ example.com&gt; * @version 1.6 版本 * @param * @return */public class Test &#123; // class body&#125;]]></content>
      <categories>
        <category>学习笔记</category>
        <category>计算机科学</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>Java</tag>
        <tag>软件工程</tag>
        <tag>数据结构</tag>
        <tag>算法</tag>
        <tag>cs61b</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法与数据结构 01 - Java | 安装 - CS61B Berkeley]]></title>
    <url>%2FNOTE-CS61B-data-structures-01-java-install%2F</url>
    <content type="text"><![CDATA[Hello World本系列资料来源于伯克利 Josh Hug 的 cs61b spring 2017和cs61b spring 2018. Java安装与配置安装Java，前往Oracle下载java sdk，我用的是Java SE 8u151/ 8u152 版本。安装sdk时会同时安装sdr。 Windows系统配置: 推荐安装git bash, 一切按照默认安装就好. 更新系统环境变量: 直接在运行中搜索Environment Variables, 选择编辑系统环境变量, 在弹出的框中选择高级-&gt;环境变量, 在弹出的框中系统变量里面 新建变量: 变量名 = JAVA_HOME, 变量值 = 你的jdk路径,如C:\Program Files\Java\jdk1.8.0_151 编辑Path: 在前面加入%JAVA_HOME%\bin;%PYTHON_HOME%;(请注意，不能有空格.) OS X系统配置: 安装Homebrew，一个非常好用的包管理工具。要安装，请在terminal终端输入ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot;(注意：在此过程中，可能会提示输入密码。当输入密码时，终端上不会显示任何内容，但计算机还是会记录你的密码的。这是一个安全措施, 让其他人在屏幕上看不到你的密码。只需输入您的密码，然后按回车。) 然后，通过输入以下命令来检查brew系统是否正常工作brew doctor. 如果遇到警告，要求下载命令行工具，则需要执行此操作。请参考这个StackOverflow。 安装git：输入brew install git 安装并配置好java后，测试是否成功:随便在你喜欢的文件夹里新建一个java文件HelloWorld.java12345public class HelloWorld &#123; public static void main(String[] args) &#123; System.out.println("Hello world!"); &#125;&#125; 你可以选择用sublime来快速新建文件, 直接在你选择的文件里右键 git bash, 在git bash 里面键入subl HelloWorld.java, 还自动启动sublime并新建一个空白的HelloWorld.java文件, 把上面的代码复制进去并保存即可. (若出现类似提示: 找不到subl command, 解决办法请参考博文在Gitbash中直接启动sublime或atom等编辑器以打开或新建文件 )开始真正的测试。直接在之前打开的git bash中输入: ls, 会看到HelloWorld.java这个文件, ls会列出这个目录中的文件/文件夹 javac HelloWorld.java, 理论上这一步不会有任何输出，有的话可能是设置有问题。现在，如果你继续ls，会看到多了一个HelloWorld.class文件， 这是javac创建的。 java HelloWorld (注意没有.java), 会看到输出Hello World, 表明你的Java设置没有问题]]></content>
      <categories>
        <category>学习笔记</category>
        <category>计算机科学</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>Java</tag>
        <tag>软件工程</tag>
        <tag>数据结构</tag>
        <tag>算法</tag>
        <tag>cs61b</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[人工智能AI入门到进阶]]></title>
    <url>%2Fai%2F</url>
    <content type="text"><![CDATA[简介记录学习AI的学习笔记，内容包含基础知识的总结以及编程实现的整理。 Language:English 目录 人工智能 机器学习 深度学习 自然语言处理 计算机视觉 机器人 大数据 MapReduce 人工智能机器学习 Coursera Machine Learning， 吴恩达的简化版机器学习 Machine Learning, 吴恩达的机器学习课程 这个比较深入 Deep Learning, 吴恩达的深度学习课程 Neural Networks for Machine Learning, Hinton的神经网络课程 深度学习 Deep learning, Coursera Machine Learning Practical: DNN, CNN, RNN 每个lab的答案在下一个lab branch里，即lab1的答案可以在lab2 branch里面看到。这个代码全部用Python class，比coursera的难度高点。 自然语言处理 自然语言处理, 斯坦福 加速自然语言处理, 爱丁堡大学 深度学习处理自然语言，斯坦福 计算机视觉 图像识别：卷积神经网络，李飞飞，斯坦福 机器人 机器人入门，斯坦福 大数据 Hadoop和MapReduce入门，优达学城 MapReduce极限计算，爱丁堡大学 并行计算入门：MPI, openMP, and CUDA, 斯坦福 参考:Guide to technical development from Google educationOS Free Programming Books]]></content>
      <categories>
        <category>学习笔记</category>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>人工智能</tag>
        <tag>自然语言处理</tag>
        <tag>机器学习</tag>
        <tag>深度学习</tag>
        <tag>计算机视觉</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS入门到进阶]]></title>
    <url>%2Fcs%2F</url>
    <content type="text"><![CDATA[简介记录学习CS的学习笔记，内容包含基础知识的总结以及编程实现的整理。 Language:English 目录 CS入门 学习编写(至少)一种面向对象编程语言(C ++，Java®，Python®) 学习其他编程语言 测试你的代码 逻辑推理和离散数学 深入了解算法和数据结构 了解计算机操作系统 CS入门现在的入门课基本都是用Python语言。 计算机科学导论，优达学城 CS50x 哈佛，语言包括C，Python，SQL和JavaScript加CSS和HTML CMU 15213: Introduction to Computer Systems (ICS) 面向对象编程语言一般而言，建议先学Java，Python，再学C++。 这三种语言都基本掌握后，再根据自身的职业需求，选择其中一个语言（或者其他语言）进一步深入练习。因为学校课程主要以Python为主，所以目前我还是主要深入学习Python，这是我的Python学习笔记。 面向初学者程序员的在线资源： 编程方法学，斯坦福CS106A，Java 伯克利大学CS 61A计算机程序的结构与解读，Python Java编程简介，MIT Google的Python Class Google的C ++类 面向有经验的程序员的在线资源： 数据结构，伯克利大学 CS 61B，Java 计算机程序设计，Udacity，Python 抽象编程，斯坦福 CS106B，C ++最新作业：http://web.stanford.edu/class/cs106b/ 《数据结构与算法分析:C++描述》, Mark A. Weiss 其他编程语言根据实际需要自行选择一种或多种学习： JavaScript® CSS＆HTML Ruby® Lua PHP® Haskell Perl® Go Shell®脚本 Lisp® Scheme® 一些在线资源： CS50x 哈佛，语言包括C，Python，SQL和JavaScript加CSS和HTML Codecademy JavaScript Bento JavaScript Learning Track(Bento) Egghead.io 学习如何编程：JavaScript - Epicodus Inc. 学习：查询 CSS ＆ HTML Bento CSS Learning Track(Bento) Bento HTML Learning Track(Bento) 用破折号建立个人网站 使用Webflow构建响应式网站 使用骨架构建SaaS着陆页 建立动态网站 在1小时内编写个人启动页面：实用HTML和CSS简介 学习如何编程：CSS - Epicodus Inc. 从头开始学习HTML5编程 Ruby 学习如何编程：Ruby - Epicodus Inc. RubyMonk - 交互式Ruby教程 Haskell C9：功能编程基础知识 - Erik Meijer CIS 194：Haskell简介 - Brent Yorgey CS240h：Haskell的功能系统 - Bryan O’Sullivan edX：功能编程简介 - Erik Meijer 亚琛大学：功能编程 - JürgenGiesl Lua Lua Interactive Crash Course Lua Tutorial PHP 学习如何编程：PHP - Epicodus Inc. GO Go Tutorial 测试你的代码了解如何捕获错误，创建测试和破解软件. 软件测试，Udacity 软件调试，Udacity 逻辑推理和离散数学 数学计算机科学，麻省理工学院 数学思考导论，斯坦福大学，Coursera 概率图形模型，斯坦福大学，Coursera 博弈论，斯坦福大学和不列颠哥伦比亚大学，Coursera 算法和数据结构了解基本数据类型(堆栈，队列和袋子)，排序算法(快速排序，合并，堆栈)，数据结构(二叉搜索树，红黑树，哈希表)和Big O. 算法简介，麻省理工学院，2011秋季 算法，普林斯顿大学，Part 1 ＆ Part2 算法：设计和分析，斯坦福大学 算法，第4版，by Robert Sedgewick and Kevin Wayne 参考:Guide to technical development from Google educationOS Free Programming Books]]></content>
      <categories>
        <category>学习笔记</category>
        <category>计算机科学</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>软件工程</tag>
        <tag>计算机科学</tag>
      </tags>
  </entry>
</search>
