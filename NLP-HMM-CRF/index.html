<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="google-site-verification" content="0p5a0VOKCc8etsdDimlaZoAC96x8VeV9Ab5HWs5NcVw" />








  <meta name="baidu-site-verification" content="EbMAKHjVzF" />







  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="NLP," />










<meta name="description" content="序列标注（Sequence Labeling）序列标注任务是指根据观察得到的序列（如一个句子）, 推断出序列每个元素（单词）对应的标注。 具体的任务包括分词(Segmentation), 词性标注（Part-of-Speach tagging, POS）, 实体识别(Named Entity Recognition, NER), 等等. 所谓POS, 就是对于一个句子, 如Bob drank co">
<meta name="keywords" content="NLP">
<meta property="og:type" content="article">
<meta property="og:title" content="概率图模型 - 朴素贝叶斯 - 隐马尔科夫 - 条件随机场 - 逻辑回归">
<meta property="og:url" content="https://congchan.github.io/NLP-HMM-CRF/index.html">
<meta property="og:site_name" content="Computer Science &amp; AI">
<meta property="og:description" content="序列标注（Sequence Labeling）序列标注任务是指根据观察得到的序列（如一个句子）, 推断出序列每个元素（单词）对应的标注。 具体的任务包括分词(Segmentation), 词性标注（Part-of-Speach tagging, POS）, 实体识别(Named Entity Recognition, NER), 等等. 所谓POS, 就是对于一个句子, 如Bob drank co">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://congchan.github.io/images/probabilistic_graphical_models.png">
<meta property="og:image" content="https://congchan.github.io/images/HMM-MEMM.png">
<meta property="og:image" content="https://congchan.github.io/images/HMM-like-linear-chain-crf.png">
<meta property="og:image" content="https://congchan.github.io/images/linear-chain-crf.png">
<meta property="og:image" content="https://congchan.github.io/images/linear-chain-crf-depend-on-current-observation.png">
<meta property="og:image" content="https://congchan.github.io/images/linear-chain-crf-depend-on-all-observations.png">
<meta property="og:image" content="https://congchan.github.io/images/人名指界词.png">
<meta property="og:image" content="https://congchan.github.io/images/人名识别特征原子模板.png">
<meta property="og:image" content="https://congchan.github.io/images/relationship_nbs_hmm_lr_crf.png">
<meta property="og:updated_time" content="2020-03-09T09:53:08.599Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="概率图模型 - 朴素贝叶斯 - 隐马尔科夫 - 条件随机场 - 逻辑回归">
<meta name="twitter:description" content="序列标注（Sequence Labeling）序列标注任务是指根据观察得到的序列（如一个句子）, 推断出序列每个元素（单词）对应的标注。 具体的任务包括分词(Segmentation), 词性标注（Part-of-Speach tagging, POS）, 实体识别(Named Entity Recognition, NER), 等等. 所谓POS, 就是对于一个句子, 如Bob drank co">
<meta name="twitter:image" content="https://congchan.github.io/images/probabilistic_graphical_models.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://congchan.github.io/NLP-HMM-CRF/"/>





  <title>概率图模型 - 朴素贝叶斯 - 隐马尔科夫 - 条件随机场 - 逻辑回归 | Computer Science & AI</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Computer Science & AI</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://congchan.github.io/NLP-HMM-CRF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Cong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Computer Science & AI">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">概率图模型 - 朴素贝叶斯 - 隐马尔科夫 - 条件随机场 - 逻辑回归</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-12-16T00:00:00+08:00">
                2018-12-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index">
                    <span itemprop="name">AI</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/NLP/" itemprop="url" rel="index">
                    <span itemprop="name">NLP</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/NLP-HMM-CRF/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="NLP-HMM-CRF/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/NLP-HMM-CRF/" class="leancloud_visitors" data-flag-title="概率图模型 - 朴素贝叶斯 - 隐马尔科夫 - 条件随机场 - 逻辑回归">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words&#58;</span>
                
                <span title="Words">
                  7,099
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Estimated &asymp;</span>
                
                <span title="Estimated">
                  29 min
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="序列标注（Sequence-Labeling）"><a href="#序列标注（Sequence-Labeling）" class="headerlink" title="序列标注（Sequence Labeling）"></a>序列标注（Sequence Labeling）</h2><p>序列标注任务是指根据观察得到的序列（如一个句子）, 推断出序列每个元素（单词）对应的标注。</p>
<p>具体的任务包括分词(Segmentation), 词性标注（Part-of-Speach tagging, POS）, 实体识别(Named Entity Recognition, NER), 等等. 所谓POS, 就是对于一个句子, 如<code>Bob drank coffee at Starbucks</code>, 标注可能为<code>Bob (NOUN) drank (VERB) coffee (NOUN) at (PREPOSITION) Starbucks (NOUN)</code>.</p>
<p>除此之外, 还有其他涉及到需要根据观察序列推断隐含状态的问题, 这种问题的特点是每一个位置的标签都不是独立的, 而是和上下文相关依存的, 可以用序列标注的思路来处理. </p>
<p>单个分类器仅能预测单个类变量，但是序列标注基于概率图模型, 图模型(Graphical Models)的真正功能在于它们能够对许多有相互依赖的变量进行建模。最简单的依赖关系可以描述为一种线性链(Linear Chain), 也就是后续介绍到的隐马尔可夫模型(Hidden Markov Model, HMM)用到的假设.</p>
<a id="more"></a>
<h2 id="概率图模型"><a href="#概率图模型" class="headerlink" title="概率图模型"></a>概率图模型</h2><p>Graphical Models, 用图的形式表示随机变量之间条件依赖关系的概率模型，是概率论与图论的结合。图中的节点表示随机变量，缺少边表示条件独立假设。</p>
<p>G = (V, E). 其中 V: vertex, 顶点/节点, 表示随机变量. E: edge, 边/弧. 如果两个节点不存在边, 则二者条件独立.<br><img src="/images/probabilistic_graphical_models.png" alt="" title="image from: Probabilistic Graphical Models Principles and Techniques"> 从图上可以看到, 贝叶斯网络(Bayesian Networks, BNs)是有向图, 每个节点的条件概率分布表示为<code>P(当前节点 | 父节点)</code>.</p>
<p>而马尔可夫网络则是<strong>无向图</strong>. 无向图形模型是指一整个家族的概率分布，每个概率分布都根据给定的因子集合进行因式分解。一般用<strong>random field</strong>来指代无向图中定义的特定分布. 数学上表达无向图, 指给定子集$\{Y_a \}_{a=1}^A$, 对于所有$\mathbf{y}_a$和任何因子选项$\mathcal{F}=\{\Psi_a\}$, $\Psi_a(\mathbf{y}_a) \geq 0$, 无向图定义的各个分布可以写成:</p>
<p>$$p(\mathbf{y})=\frac{1}{Z} \prod_{a=1}^A \Psi_{a}\left(\mathbf{y}_{a}\right)$$</p>
<p>Z是正则项用于保证分布$p$和为$1$<br>$$Z=\sum_{\mathbf{y}} \prod_{a=1}^{A} \Psi_{a}\left(\mathbf{y}_{a}\right)$$</p>
<p>Markov Net 包含了一组具有马尔可夫性质的随机变量. <strong>马尔可夫随机场(Markov Random Fields, MRF)</strong>是由参数$λ=(S, π, A)$表示, 其中S是状态的集合，π是初始状态的概率, A是状态间的转移概率。一阶马尔可夫链就是假设t时刻的状态只依赖于前一时刻的状态，与其他时刻的状态和观测无关。这个性质可以用于简化概率链的计算。使用类似性质作为假设的模型还有Bi-gram语言模型等.</p>
<h3 id="朴素贝叶斯分类器与隐马尔可夫模型"><a href="#朴素贝叶斯分类器与隐马尔可夫模型" class="headerlink" title="朴素贝叶斯分类器与隐马尔可夫模型"></a>朴素贝叶斯分类器与隐马尔可夫模型</h3><p>朴素贝叶斯分类器(NBs)假设条件独立性(朴素贝叶斯假设, Hand and Yu, 2001)：$p(x_i | y, x_j) = p(x_i | y)$, 在给定目标值 y 时，x的属性值之间相互条件独立。这样, 计算可以简化为<br>$$p(y | \overrightarrow{x}) \propto p(y, \overrightarrow{x}) = p(y) \prod_{i=1} p(x_i | y).$$</p>
<p>朴素贝叶斯模型只考虑了单个输出变量y。如果要为一个观察序列$\overrightarrow{x} =(x_1, …, x_n)$预测对应的分类序列$\overrightarrow{y} =（y_1, …, y_n)$ ，一个简单的序列模型可以表示为多个NBs的乘积。此时不考虑序列单个位置之间的相互依赖。$$p(\overrightarrow{y}, \overrightarrow{x}) = \prod^n_{i=1} p(y_i) p(x_i | y_i).$$<br>此时每个观察值$x_i$仅取决于对应序列位置的类变量$y_i$。由于这种独立性假设，从一个步骤到另一个步骤的转换概率不包括在该模型中。然而这种假设在实践中几乎不会符合，这导致这种模型的性能很有限。</p>
<p>因此，比较合理的假设是观测序列在连续相邻位置间的状态存在依赖。要模拟这种依赖关系, 就要引入状态转移概率$p(y_i | y_{i-1})$, 由此引出著名的隐马尔可夫模型 Hidden Markov model, HMM, Rabiner (1989).</p>
<p>HMM参数$λ = (Y, X, π, A, B)$ ，其中Y是隐状态（输出变量）的集合，X是观察值（输入）集合，π是初始状态的概率，A是状态转移概率矩阵$p(y_i | y_{i-1})$，B是输出观察值概率矩阵$p(x_i | y_{i})$。在POS任务中, X就是观察到的句子, Y就是待推导的标注序列, 因为词性待求的, 所以人们称之为<strong>隐含状态</strong>.</p>
<p>概括一下HMM设定的假设:</p>
<ol>
<li>Markov assumption：假设每个状态仅依赖于其前一个状态, $p(y_t|y_{t−1})$</li>
<li>Stationarity assumption：状态的转换概率与转换发生的实际时间（实际输入）无关</li>
<li>Output independence assumption: 假设每一个观察值x仅依赖于当前状态值y, $p(x_t|y_t)$, 而与前面的观察值无关。</li>
</ol>
<p>那么状态序列y和观察序列x的联合概率可以分解为<br>$$p(\mathbf{y}, \mathbf{x})=\prod_{t=1}^{\mathrm{T}} p\left(y_{t} | y_{t-1}\right) p\left(x_{t} | y_{t}\right)$$</p>
<p>总的来说, 隐马尔可夫模型（HMM）是具有随机状态转移和观测值的有限状态自动机（Rabiner，1989）。自动机对概率生成过程进行建模: 先从某个初始状态开始，发射(emit)该状态生成的观察值，再转移到下一个状态，再发射另一个观察值，以此类推，直到达到指定的最终状态，从而产生一系列观察值。</p>
<p>HMM作为生成式的概率模型, 对观察特征的条件独立约束非常严格. 而且为了定义观察值序列和序列标记的联合概率，生成模型需要枚举所有可能的观察序列. 对于表示多个相互作用的特征或观测值的长距离相关性, 这种枚举是不切实际的，因为此类模型的inference很棘手。但很多任务往往受益于这种相互作用、相互交叉重叠的特征，比如除了传统的单词自身外，还有大小写，单词结尾，词性，格式，在页面上的位置以及WordNet中的节点成员身份等等。</p>
<p>除此之外, 大部分文本任务是根据给定的观察序列（如纯文本）来预测对应的状态序列，也就是判别问题。换句话说，HMM不恰当地用了生成联合概率的模型去判别问题。</p>
<h3 id="隐马尔可夫模型到最大熵马尔可夫模型"><a href="#隐马尔可夫模型到最大熵马尔可夫模型" class="headerlink" title="隐马尔可夫模型到最大熵马尔可夫模型"></a>隐马尔可夫模型到最大熵马尔可夫模型</h3><p>最大熵马尔可夫模型(Maximum Entropy Markov Models, MEMM)跟HMM的生成式概率图不同，MEMM对当前状态的判断依赖于前一时间步的状态和当前观察值的状态。<img src="/images/HMM-MEMM.png" alt="" title="image from McCallum, A. (1909)"></p>
<p>首先所谓”熵”就是信息论中的概念:</p>
<blockquote>
<p>Entropy: the uncertainty of a distribution.</p>
</blockquote>
<p>量化Entropy: surprise.<br>Entropy = expected surprise</p>
<p>Event $x$,<br>Probability $p_x$,<br>“Surprise” $log(1/p_x)$,<br>Entropy:<br>$$<br>\begin{aligned}<br>&amp;H(p)=E_{p}\left[\log \frac{1}{p_{x}}\right]\\<br>&amp;\mathrm{H}(p)=-\sum_{x} p_{x} \log p_{x}<br>\end{aligned}<br>$$</p>
<p>熵最大的分布就是均匀分布，也就是每一个选项都一样，等于什么信息都没给。如果给了额外的信息，如约束，特征之后，熵就可以降低。</p>
<p>“最大熵”是指遵循最大熵原则：</p>
<blockquote>
<p>model all that is known and assume nothing about that which is unknown.</p>
</blockquote>
<p>也就说, 如果给定了一组事实，我们最好选择一个符合这些事实的模型，剩余情况则尽可能地一视同仁不做任何区别对待。最佳的模型是符合训练数据衍生的约束条件的模型，同时尽可能少地做假设，也就是少做承诺，也就避免过拟合。</p>
<p>MEMM 把HMM中的转移概率和发射概率替换为一个概率：当前状态$s$依赖于前一个状态$s^{\prime}$和当前观察值$o$, $\mathrm{P}\left(s | s^{\prime}, o\right)$</p>
<p>MEMM的训练思路是这样: 对每个状态$s^{\prime}$, 将训练数据分为<code>&lt;观察-目标状态&gt;对</code> $&lt;o, s&gt;$, 也就是把 $\mathrm{P}\left(s | s^{\prime}, o\right)$ 分成 $|S|$ 个分别训练的exponential model $\mathrm{P}_{s^{\prime}}(s | o)=\mathrm{P}\left(s | s^{\prime}, o\right)$, 再通过最大化熵来训练exponential models, 换种说法叫<code>logistic regression classifier</code>.</p>
<p>用的约束条件是学习分布中每个特征$a$的期望值与训练数据的观测序列上每个特征的期望值相同. 满足这些约束的最大熵分布（Della Pietra，Della Pietra和Lafferty，1997）是唯一的，与最大似然分布一致，对每一个位置的状态$s^{\prime}$, 具有指数形式：<br>$$<br>\mathrm{P}_{s^{\prime}}(s | o)=\frac{1}{Z\left(o, s^{\prime}\right)} \exp \left(\sum_{a} \lambda_{a} f_{a}(o, s)\right)<br>$$<br>其中$\lambda_{a}$是待估计的参数, $Z\left(o, s^{\prime}\right)$是归一化因子<br>$$<br>Z\left(o, s^{\prime}\right)=\sum_{s \in S} P\left(s | s^{\prime}, o\right)<br>$$<br>$S$是标签集.</p>
<p>如果把问题简化为线性的相邻依赖, 那么每一个状态$s_{i}$仅依赖于前一个状态$s_{i-1}$. 用$Y$表达标签序列, 用$X$表达观察序列, 那么<br>$$P\left(y_{1}, y_{2}, \ldots, y_{n} | \boldsymbol{x}\right)=P\left(y_{1} | \boldsymbol{x}\right) P\left(y_{2} | \boldsymbol{x}, y_{1}\right) P\left(y_{3} | \boldsymbol{x}, y_{2}\right) \ldots P\left(y_{n} | \boldsymbol{x}, y_{n-1}\right)$$<br>其中<br>$$P\left(y_{1} | \boldsymbol{x}\right)=\frac{e^{f\left(y_{1} ; \boldsymbol{x}\right)}}{\sum_{y_{1} \in S} e^{f\left(y_{k} ; \boldsymbol{x}\right)}}, \quad P\left(y_{k} | \boldsymbol{x}, y_{k-1}\right)=\frac{e^{g\left(y_{k-1}, y_{k}\right)+f\left(y_{k} ; \boldsymbol{x}\right)}}{\sum_{y_{k} \in S} e^{g\left(y_{k-1}, y_{k}\right)+f\left(y_{k} ; \boldsymbol{x}\right)}}$$<br>则<br>$$P(\boldsymbol{y} | \boldsymbol{x})=\frac{e^{f\left(y_{1} ; \boldsymbol{x}\right)+g\left(y_{1}, y_{2}\right)+f\left(y_{2} ; \boldsymbol{x}\right)+\cdots+g\left(y_{n-1}, y_{n}\right)+f\left(y_{n} ; \boldsymbol{x}\right)}}{\left(\sum_{y_{1} \in S} e^{f\left(y_{1} ; \boldsymbol{x}\right)}\right)\left(\sum_{y_{2} \in S} e^{g\left(y_{1}, y_{2}\right)+f\left(y_{2} ; \boldsymbol{x}\right)}\right) \cdots\left(\sum_{y_{n} \in S} e^{g\left(y_{n-1}, y_{n}\right)+f\left(y_{n} ; \boldsymbol{x}\right)}\right)}$$<br>MEMM将整体的概率分布分解为每一个时间步的分布之积，所以算loss只需要把每一步的交叉熵求和。只需要每一步单独执行softmax，所以MEMM是完全可以并行的，速度跟直接逐步Softmax基本一样。</p>
<p>虽然MEMM能克服HMM的很多弱点, 但是MEMM自身也有一个 <strong>label bias</strong> 问题, 就是标签偏差, 离开给定状态的转移仅相互对比，而不是与全局所有其他转移对比。转移分数是分别对每个状态的归一化, 这意味到达一个状态的所有质量必须在可能的后续状态之间分配。观察值可以影响哪个目标状态获得质量，但无法影响多少质量可以被传递。这会导致模型偏向输出选择较少的状态, 比如极端情况下, 在训练集中某个状态$s_a$只发现了有一种可能的转移$s_b$, 那么状态$s_a$别无选择，只能将所有质量传递给它的唯一transition output $s_b$。那么后续在预测时, 。</p>
<h3 id="MEMM到CRF"><a href="#MEMM到CRF" class="headerlink" title="MEMM到CRF"></a>MEMM到CRF</h3><p>CRF再拥有MEMM的优点的同时, 克服了MEMM的缺点. CRF和MEMM的关键区别在于，MEMM使用每个状态的指数模型来确定给定当前状态的下一状态的条件概率，而CRF则使用一个指数模型来表示整个标签序列的联合概率, 这个概率条件依赖于给定的完整观察序列。因此，在不同状态下，不同特征的权重可以相互抵消。也就是说CRF是一个以观测序列$X$为全局条件的随机场.</p>
<p>如果把问题简化为线性链, CRF把y看成一个整体，截至每一个时间步$n$, 通过统计所有特征可以得一个总分<br>$$\begin{aligned}<br>f\left(y_{1}, y_{2}, \ldots, y_{n} ; \boldsymbol{x}\right) &amp;=f\left(y_{1} ; \boldsymbol{x}\right)+g\left(y_{1}, y_{2}\right)+\cdots+g\left(y_{n-1}, y_{n}\right)+f\left(y_{n} ; \boldsymbol{x}\right) \\<br>&amp;=f\left(y_{1} ; \boldsymbol{x}\right)+\sum_{k=2}^{n}\left(g\left(y_{k-1}, y_{k}\right)+f\left(y_{k} ; \boldsymbol{x}\right)\right)<br>\end{aligned}$$<br>其中$g\left(y_{k-1}, y_{k}\right)$是转移矩阵</p>
<p>可以得到对应得概率是<br>$$P(\boldsymbol{y} | \boldsymbol{x})=\frac{e^{f\left(y_{1}, y_{2}, \ldots, y_{n} ; \boldsymbol{x}\right)}}{\sum_{y_{1}, y_{2}, \ldots, y_{n} \in S^n} e^{f\left(y_{1}, y_{2}, \ldots, y_{n} ; \boldsymbol{x}\right)}}$$<br>CRF的计算困难之处在于上式的分母项包含了所有可能路径$S^n$的求和，搜索空间非常庞大.</p>
<p>线性链CRF和线性链MEMM比较, 区别仅在于分母（也就是归一化因子）的计算方式不同，CRF的是全局归一化的，而MEMM的是局部归一化的.</p>
<h3 id="隐马尔可夫模型到CRF"><a href="#隐马尔可夫模型到CRF" class="headerlink" title="隐马尔可夫模型到CRF"></a>隐马尔可夫模型到CRF</h3><p>HMM和CRF的对应关系类似于Naive-Bayes和Logistics regression, 都是生成式和判别式的对比. HMM则采用生成式方法进行标签生成, CRF将各种特征组合在一起判断标签. HMM可以推演出特定形式的CRF. 把上式的HMM改写成如下形式:</p>
<p>$$<br>\begin{aligned}<br>    p(\mathbf{y}, \mathbf{x})=&amp; \frac{1}{Z} \prod_{t=1}^T \exp \left( \sum_{i, j \in S} \theta_{i j} \mathbf{1}_{\{y_t=i\}} \mathbf{1}_{\{y_{t-1}=j\}} \right. \\\<br>    &amp;\left.+ \sum_{i \in S} \sum_{o \in O} \mu_{o i} \mathbf{1}_{\{y_{t}=i\}} \mathbf{1}_{\{x_{t}=o\}} \right)<br>\end{aligned}<br>$$<br>其中$\theta=\{\theta_{i j}, \mu_{o i}\}$是分布的实参数, $Z$是常数正则项.<br>$$<br>\begin{aligned}<br>    \theta_{i j} &amp;=\log p\left(y^{\prime}=i | y=j\right) \\\\<br>    \mu_{o i} &amp;=\log p(x=o | y=i) \\\\<br>    Z &amp;=1<br>\end{aligned}<br>$$</p>
<p>HMM是生成式的, 借鉴Naive Bayes 到 logistics regression的方式, 通过引入特征函数这个概念, $f_{k}\left(y_{t}, y_{t-1}, x_{t}\right)$, 对于每一个$(i, j)$跳转, 加入特征函数$f_{i j}\left(y, y^{\prime}, x\right)=\mathbf{1}_{\{y=i\}} \mathbf{1}_{\{y^{\prime}=j\}}$, 对于每一个<code>状态-观察值</code>对$(i,o)$, 加入特征函数$f_{i o}\left(y, y^{\prime}, x\right)=1_{\{y=i\}} \mathbf{1}_{\{x=o\}}$. 以上特征函数统一表示为$f_k$, 那么可以进一步把HMM写成:</p>
<p>$$p(\mathbf{y}, \mathbf{x})=\frac{1}{Z} \prod_{t=1}^{T} \exp \left(\sum_{k=1}^{K} \theta_{k} f_{k}\left(y_{t}, y_{t-1}, x_{t}\right)\right)$$</p>
<p>可以得出条件概率$p(y|x)$</p>
<p>$$p(\mathbf{y} | \mathbf{x})=\frac{p(\mathbf{y}, \mathbf{x})}{\sum_{\mathbf{y}^{\prime}} p\left(\mathbf{y}^{\prime}, \mathbf{x}\right)}=\frac{\prod_{t=1}^{T} \exp \left(\sum_{k=1}^{K} \theta_{k} f_{k}\left(y_{t}, y_{t-1}, x_{t}\right)\right)}{\sum_{\mathbf{y}^{\prime}} \prod_{t=1}^{T} \exp \left(\sum_{k=1}^{K} \theta_{k} f_{k}\left(y_{t}^{\prime}, y_{t-1}^{\prime}, x_{t}\right)\right)}$$</p>
<p>所以当联合概率$p(y,x)$以HMM的形式因式分解, 则关联的条件分布$p(y|x)$就是一种特定形式的linear-chain CRF，即一种仅使用当前单词自身作为特征的CRF. <img src="/images/HMM-like-linear-chain-crf.png" alt="" title="Graphical model of the HMM-like linear-chain CRF. by Sutton, C. 2010"></p>
<h2 id="Linear-Chain-CRF"><a href="#Linear-Chain-CRF" class="headerlink" title="Linear Chain CRF"></a>Linear Chain CRF</h2><p>随机场, 可以看成是一组随机变量的集合（这组随机变量对应同一个样本空间）。当给每一个位置按照某种分布随机赋予一个值之后，其全体就叫做随机场。这些随机变量之间可能有依赖关系，一般来说，也只有当这些变量之间有依赖关系的时候，我们将其单独拿出来看成一个随机场才有实际意义。</p>
<p>如果给定的MRF中每个随机变量下面还有观察值，我们要确定的是给定观察集合下，这个MRF的分布，也就是<strong>条件分布</strong>，那么这个MRF就称为 Conditional random fields (CRF)。它的条件分布形式完全类似于MRF的分布形式，只不过多了一个观察集合X。所以, CRF本质上是给定了条件(观察值observations)集合的MRF.</p>
<p>1.特征函数的选择: 特征函数的选取直接关系模型的性能。<br>2.参数估计: 从已经标注好的训练数据集学习条件随机场模型的参数，即各特征函数的权重向量λ。<br>3.模型推断: 在给定条件随机场模型参数λ下，预测出最可能的状态序列。</p>
<p>HMM的生成式概率模型是$p(y,x)$, 它的条件概率$p(y|x)$本质上就是选取了特定特征函数的CRF. 直接引用(Sutton, C. 2010)的定义:<br><img src="/images/linear-chain-crf.png" alt="" title="from: An Introduction to Conditional Random Fields, by Charles Sutton and Andrew McCallum"></p>
<p>在这里仅讨论Linear-Chain CRF, 不讨论General CRFs(太抽象,我也没完全搞懂)</p>
<p>在CRF中，首先需要定义特征函数. </p>
<p>然后为每个特征函数$f_{j}$分配权重$\lambda_j$, 权重是从数据中学习而来. 对$j$个特征方程求和, 对序列每个位置$i$求和:</p>
<p>$$ score(l | s) = \sum_{j = 1}^m \sum_{i = 1}^n \lambda_j f_j(s, i, l_i, l_{i-1})$$</p>
<p>CRF的每个特征函数都是一个输入的函数, 对应的输出是一个实数值（只是0或1）。例如, 选择特征函数$f_1(s, i, l_i, l_{i-1}) = 1$, 当且仅当$l_i = ADVERB$, 且第i个单词以“<code>-ly</code>”结尾; 否则为0. 如果与此特征相关的权重$\lambda_j$很大且为正，那么这个特征等同于说模型倾向于把以<code>-ly</code>结尾的单词标记为ADVERB。</p>
<p>通过指数化和归一化把这些得分转换为概率值:<br>$$p(l | s) = \frac{exp\left(score(l|s)\right)}{\sum_{l^\prime} exp\left(score(l^\prime|s)\right)} = \frac{exp\left(\sum_{j = 1}^m \sum_{i = 1}^n \lambda_j f_j(s, i, l_i, l_{i-1})\right)}{\sum_{l’} exp\left(\sum_{j = 1}^m \sum_{i = 1}^n \lambda_j f_j(s, i, l^\prime_i, l^\prime_{i-1})\right)} $$</p>
<p>Linear-Chain CRF特征函数的定义非常灵活, 不同的形式用于不同的功能. 比如对于HMM而言, 不管输入怎么变, 状态转换$transition(i, j)$的分值是一样的$\log p (y_t = j | y_{t−1} = i)$; 那么此时在CRF中, 我们通过增加这样一个特征$\mathbf{1}_{\{y_{t}=j\}} \mathbf{1}_{\{y_{t-1}=1\}} \mathbf{1}_{\{x_{t}=o\}}$, 使$transition(i, j)$分值依赖于当前的观察序列:<img src="/images/linear-chain-crf-depend-on-current-observation.png" alt="" title="from: An Introduction to Conditional Random Fields, by Charles Sutton and Andrew McCallum"></p>
<p>这种特征常常用于文本处理中, 比如:</p>
<ol>
<li>一个句子提供观察值$x_{i-1, i}$</li>
<li>单词的标签$y_{i-1, i}$</li>
</ol>
<p>需要指出的是在线性链CRF的定义中每个feature的依赖值并不仅限于当前和上一时间步的观察值. 事实上, 因为CRF并不表达变量之间的依赖关系, 我们可以让因子$\Psi_{t}$依赖于整个观察向量$x$并保持线性图结构, 这时候的特征函数就是$f_{k}\left(y_{t}, y_{t-1}, \mathbf{x}\right)$, 可以自由检视所有输入变量$x$, <img src="/images/linear-chain-crf-depend-on-all-observations.png" alt="" title="from: An Introduction to Conditional Random Fields, by Charles Sutton and Andrew McCallum"> 这个特性可以拓展到所有CRFs而不仅限于线性链CRF.</p>
<h3 id="CRF与HMM"><a href="#CRF与HMM" class="headerlink" title="CRF与HMM"></a>CRF与HMM</h3><p>只需要在CRF的对数线性形式中, 设置权重为对应HMM取对数后的二元转换和发射概率: $\log p(l,s) = \log p(l_0) + \sum_i \log p(l_i | l_{i-1}) + \sum_i \log p(w_i | l_i)$</p>
<ul>
<li>对于HMM的每个状态转换概率$p(l_i = y | l_{i-1} = x)$, CRF定义一组特征函数为$f_{x,y}(s, i, l_i, l_{i-1}) = 1$ 如果 $l_i = y$ 且 $l_{i-1} = x$, 为这些特征赋予权重$w_{x,y} = \log p(l_i = y | l_{i-1} = x)$</li>
<li>类似的, 对于HMM的每个发射概率$p(w_i = z | l_{i} = x)$, CRF定义一组特征函数为$g_{x,y}(s, i, l_i, l_{i-1}) = 1$ 如果 $w_i = z$ 且 $l_i = x$, 赋予权重$w_{x,z} = \log p(w_i = z | l_i = x)$.</li>
</ul>
<p>如此, CRF计算的分值$p(l|s)$就精确地正比于对应的HMM, 也就是说, 任意的HMM都可以由CRF表达出来.</p>
<p>CRF比HMM更强大, 更广泛</p>
<ol>
<li>CRF可以定义更广泛的特征函数：HMM受限于相邻位置的状态转换（二元转换）和发射概率函数，迫使每个单词仅依赖于当前标签，并且每个标签仅依赖于前一个标签。而CRF可以使用更多样的全局特征。例如，如果句子的结尾包含问号，则可以给给CRF模型增加一个特征函数，记录此时将句子的第一个单词标记为VERB的概率。这使得CRF可以使用长距离依赖的特征。</li>
<li>CRF可以有任意的权重值：HMM的概率值必须满足特定的约束， $0 &lt;= p(w_i | l_i) &lt;= 1, \sum_w p(w_i = w | l_1) = 1)$, 而CRF的权重值是不受限制的。</li>
</ol>
<p>CRF既具有判别式模型的优点，又考虑到长距离上下文标记间的转移概率，以序列化形式进行全局参数优化和解码的特点，解决了其他判别式模型(如MEMM)难以避免的标记偏见问题。</p>
<h3 id="CRF与Logistic-Regression"><a href="#CRF与Logistic-Regression" class="headerlink" title="CRF与Logistic Regression"></a>CRF与Logistic Regression</h3><p>CRF的概率计算与Logistic Regression (LR)的形式类似，<br>$$CRF: p(l | s) = \frac{exp \left(\sum_{j = 1}^m \sum_{i = 1}^n \lambda_j f_j(s, i, l_i, l_{i-1})\right)}{\sum_{l’} exp\left(\sum_{j = 1}^m \sum_{i = 1}^n \lambda_j f_j(s, i, l^\prime_i, l^\prime_{i-1})\right)}$$</p>
<p>$$LR: P(y|x) = \frac{\exp \bigg( \sum\limits_{i=1}^{N} w_{i} \cdot f_{i}(x,y) \bigg)} {\sum\limits_{y’ \in Y} \exp \bigg( \sum\limits_{i=1}^{N} w_{i} \cdot f_{i}(x,y’) \bigg)}$$<br>在LR中, $f_i(y, x)$是一个特征，$w_i$是与该特征相关的权重。提取的特征是二元特征，取值0或1，通常称为指示函数。这些特征中的每一个都由与输入$x$和分类$y$相关联的函数计算。</p>
<p>实际上，CRF基本上就是逻辑回归的序列化：与逻辑回归是用于分类的对数线性模型不同，CRF是标签序列的对数线性模型。</p>
<h3 id="CRF模型训练"><a href="#CRF模型训练" class="headerlink" title="CRF模型训练"></a>CRF模型训练</h3><p>如何通过数据训练CRF模型, 估计特征函数的权重? 利用极大似然估计（Maximum Likelihood Estimation，MLE)和梯度优化(gradient descent).</p>
<p>$\log p(l | s)$相对于参数$λ_i$的梯度为:$$\frac{\partial}{\partial w_j} \log p(l | s) = \sum_{j = 1}^m f_i(s, j, l_j, l_{j-1}) - \sum_{l’} p(l’ | s) \sum_{j = 1}^m f_i(s, j, l^\prime_j, l^\prime_{j-1})$$<br>导数的第一项是真实标签下的特征$f_i$的贡献，第二项是当前模型下特征$f_i$的期望贡献。</p>
<p>对于一堆训练样例（句子和相关的词性标签）。随机初始化CRF模型的权重。要将这些随机初始化的权重转移到正确的权重，对于每个训练示例:</p>
<ul>
<li>遍历每个特征函数$f_i$，计算训练示例相对于$λ_i$的对数概率的梯度</li>
<li>以learning rate $\alpha$的速率沿梯度方向不断修正$λ_i$: $\lambda_i = \lambda_i + \alpha [\sum_{j = 1}^m f_i(s, j, l_j, l_{j-1}) - \sum_{l’} p(l’ | s) \sum_{j = 1}^m f_i(s, j, l^\prime_j, l^\prime_{j-1})]$</li>
<li>重复这些训练步骤，直到满足停止条件（例如，更新低于某个阈值）。</li>
</ul>
<p>CRF的缺点是模型训练时收敛速度比较慢.</p>
<p>训练后的CRF模型, 可以用于预测一个未标记序列的最大可能标记. 我们需要每个标记的概率$p(l | s)$, 对于大小为k的标签集和长度为m的句子, 需要比较的$p(l | s)$组合有$k^m$种. 但是计算时, 可以利用动态规划的方法, 原理类似于Viterbi算法.</p>
<h3 id="CRF中文命名实体识别"><a href="#CRF中文命名实体识别" class="headerlink" title="CRF中文命名实体识别"></a>CRF中文命名实体识别</h3><p>比如中文命名实体识别任务, 假如需要判断人名、地名、组织名三类命名实体.</p>
<p>对于人名, 通过一些模板来筛选特征。模板是对上下文的特定位置和特定信息的考虑, 适用于人名的特征模板:</p>
<ul>
<li>人名的指界词：主要包括称谓词、动词和副词等，句首位置和标点符号也可。根据指界词与人名共现的概率的大小，将人名的左右指界词各分为两级，生成4个人名指界词列表：<img src="/images/人名指界词.png" alt=""></li>
<li>人名识别特征的原子模板，每个模板都只考虑了一种因素：<img src="/images/人名识别特征原子模板.png" alt=""></li>
</ul>
<p>当特征函数取特定值时，特征模板被实例化, 就可以得到具体的特征。比如当前词的前一个词 $w_{i-1}$ 在人名1级左指界词列表中出现, $f_i(x, y) = 1, if: PBW1(w_{i-1}) = true, y = PERSON$</p>
<p>类似的，做地名、组织名的特征提取和选择，并将其实例化，得到所有的特征函数。</p>
<p>评测指标:<br>召回 recall = $ \frac{正确识别的命名实体首部（尾部）的个数}{标准结果中命名实体首部（尾部）的的总数} \times 100\%$</p>
<p>精确率 precision = $ \frac{正确识别的命名实体首部（尾部）的个数}{识别出的命名实体首部（尾部）的总数} \times 100\%$</p>
<p>F1 =  $ \frac{2 \times precision \times recall}{precision + recall}$</p>
<h3 id="谈谈生成式模型和判别式模型"><a href="#谈谈生成式模型和判别式模型" class="headerlink" title="谈谈生成式模型和判别式模型"></a>谈谈生成式模型和判别式模型</h3><p>从朴素贝叶斯, 到HMM; 从Logistic Regression到CRF, 这些概率图模型有如下转换关系:<br><img src="/images/relationship_nbs_hmm_lr_crf.png" alt="" title="Diagram of the relationship between naive Bayes, logistic regression, HMMs, linear-chain CRFs, generative models, and general CRFs. image from: An Introduction to Conditional Random Fields, by Charles Sutton and Andrew McCallum"></p>
<p>而在朴素贝叶斯与Logistic Regression, 以及HMM和CRF之间, 又有生成式和判别式的区别.</p>
<ul>
<li>生成式模型描述标签向量y如何有概率地<strong>生成</strong>特征向量x, 即尝试构建x和y的联合分布$p(y, x)$, 典型的模型有HMM，贝叶斯模型，MRF。生成式模型</li>
<li>而判别模型直接描述如何根据特征向量x判断其标签y, 即尝试构建$p(y | x)$的条件概率分布, 典型模型如如LR, SVM，CRF，MEMM等. 不构建$p(x)$是因为分类时用不到.</li>
</ul>
<p>原则上，任何类型的模型都可以使用贝叶斯规则转换为另一种类型，但实际上这些方法是不同的. 生成模型和判别模型都描述了$p(y, x)$的概率分布，但努力的方向不同。生成模型，例如朴素贝叶斯分类器和HMM，是一类可以因式分解为$p(y, x) = p(y)p(x|y)$的联合分布, 也就是说，它们描述了如何为给定标签的特征采样或“生成”值。生成式模型从统计的角度表示数据的分布情况，能够反映同类数据本身的相似度，不关心判别边界。生成式模型的优点是:<br>• 实际上带的信息要比判别模型丰富， 研究单类问题比判别模型灵活性强<br>• 能更充分的利用先验知识<br>• 模型可以通过增量学习得到<br>缺点也很明显: • 学习过程比较复杂; • 在目标分类问题中准确度不高</p>
<p>而判别式模型, 比如 LR, 是一系列条件分布$p(y | x)$. 也就是说，分类规则是直接建模的。原则上，判别模型也可通过为输入提供边际分布$p(x)$来获得联合分布$p(y, x)$，但很少需要这样。条件分布$p(y | x)$不包括$p(x)$的信息，在分类任务中其实无论如何也用不到。其次，对$p(x)$建模的困难之处在于它通常包含很多建模难度较高的有高度依赖性的特征。判别式模型寻找不同类别之间的最优分类面，反映的是异类数据之间的差异。优点是:<br>• 分类边界更灵活，比使用纯概率方法或生产模型得到的更高级。<br>• 能清晰的分辨出多类或某一类与其他类之间的差异特征<br>• 在聚类、viewpoint changes, partial occlusion and scale variations中的效果较好<br>•适用于较多类别的识别<br>缺点是：• 不能反映训练数据本身的特性。• 能力有限，可以分类, 但无法把整个场景描述出来。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><a href="http://homepages.inf.ed.ac.uk/csutton/publications/crftut-fnt.pdf" target="_blank" rel="noopener">An Introduction to Conditional Random Fields</a>, Sutton, C., &amp; McCallum, A. (2011)</li>
<li><a href="http://blog.echen.me/2012/01/03/introduction-to-conditional-random-fields/" target="_blank" rel="noopener">http://blog.echen.me/2012/01/03/introduction-to-conditional-random-fields/</a></li>
<li>Classical probabilistic models and conditional random fields</li>
<li>McCallum, A. (1909). Maximum Entropy Markov Models for Information Extraction and Segmentation. Berichte Der Deutschen Chemischen Gesellschaft, 42(1), 310–317. <a href="https://doi.org/10.1002/cber.19090420146" target="_blank" rel="noopener">https://doi.org/10.1002/cber.19090420146</a></li>
</ol>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/NLP/" rel="tag"># NLP</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/NLP-recurrent-neural-networks/" rel="next" title="循环神经网络">
                <i class="fa fa-chevron-left"></i> 循环神经网络
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/NLP-topic-modeling/" rel="prev" title="Topic Modelling - 主题建模以及隐变量模型">
                Topic Modelling - 主题建模以及隐变量模型 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
        <!-- Go to www.addthis.com/dashboard to customize your tools -->
<div class="addthis_inline_share_toolbox">
  <script type = "text/javascript" src = "//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5b35f789bd238372" async = "async" ></script>
</div>

      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.png"
                alt="Cong" />
            
              <p class="site-author-name" itemprop="name">Cong</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">92</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">10</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">43</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/congchan/" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:shooterbeta@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#序列标注（Sequence-Labeling）"><span class="nav-number">1.</span> <span class="nav-text">序列标注（Sequence Labeling）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#概率图模型"><span class="nav-number">2.</span> <span class="nav-text">概率图模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#朴素贝叶斯分类器与隐马尔可夫模型"><span class="nav-number">2.1.</span> <span class="nav-text">朴素贝叶斯分类器与隐马尔可夫模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#隐马尔可夫模型到最大熵马尔可夫模型"><span class="nav-number">2.2.</span> <span class="nav-text">隐马尔可夫模型到最大熵马尔可夫模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MEMM到CRF"><span class="nav-number">2.3.</span> <span class="nav-text">MEMM到CRF</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#隐马尔可夫模型到CRF"><span class="nav-number">2.4.</span> <span class="nav-text">隐马尔可夫模型到CRF</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Linear-Chain-CRF"><span class="nav-number">3.</span> <span class="nav-text">Linear Chain CRF</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#CRF与HMM"><span class="nav-number">3.1.</span> <span class="nav-text">CRF与HMM</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CRF与Logistic-Regression"><span class="nav-number">3.2.</span> <span class="nav-text">CRF与Logistic Regression</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CRF模型训练"><span class="nav-number">3.3.</span> <span class="nav-text">CRF模型训练</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CRF中文命名实体识别"><span class="nav-number">3.4.</span> <span class="nav-text">CRF中文命名实体识别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#谈谈生成式模型和判别式模型"><span class="nav-number">3.5.</span> <span class="nav-text">谈谈生成式模型和判别式模型</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考资料"><span class="nav-number">4.</span> <span class="nav-text">参考资料</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Cong</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://shootingspace.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'https://congchan.github.io/NLP-HMM-CRF/';
          this.page.identifier = 'NLP-HMM-CRF/';
          this.page.title = '概率图模型 - 朴素贝叶斯 - 隐马尔科夫 - 条件随机场 - 逻辑回归';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://shootingspace.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  














  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("KJ3aRNAv0BvPIe1SoKj9frht-gzGzoHsz", "gm1RJIiLJ5g6f6lmDxkpWzVG");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  

</body>
</html>
